{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CACM DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACMDATA = '../../../cacm/cacm.all'\n",
    "import re\n",
    "IDMarker = re.compile('(\\.I.)')\n",
    "allMarkers = re.compile('(\\.[ITWBACKNX] )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queries info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACMQUERY = '../../../cacm/query.text'\n",
    "CACMQRELS = '../../../cacm/qrels.text'\n",
    "import re\n",
    "queryMarkers = re.compile('(\\.[IWAN] )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(PATH, marker):\n",
    "    \"\"\"get the data from the file and split it by ID\"\"\"\n",
    "    with open(PATH, 'r') as f:\n",
    "        t = f.read().replace('\\n', ' ')\n",
    "        lines = re.split(marker, t)\n",
    "        lines.pop(0)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte CACM.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacmData = getData(CACMDATA, allMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFrame = pd.DataFrame(columns=['.I','.T','.W','.B','.A','.K','.C','.N','.X'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.W': None,\n",
    "    '.B': None,\n",
    "    '.K': None,\n",
    "    '.C': None,\n",
    "    '.A': None,\n",
    "    '.N': None,\n",
    "    '.X': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cacmData), 2):\n",
    "    if (notTheFirst and cacmData[i].strip() == '.I'):\n",
    "        dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cacmData[i].strip()] = cacmData[i+1].strip()\n",
    "    notTheFirst = True\n",
    "dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "dataFrame.set_index('.I', inplace=True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.to_csv('../../cacmData/cacmCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte query.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacmQuery = getData(CACMQUERY, queryMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qDataFrame = pd.DataFrame(columns=['.I','.W','.A','.N'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.W': None,\n",
    "    '.A': None,\n",
    "    '.N': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cacmQuery), 2):\n",
    "    if (notTheFirst and cacmQuery[i].strip() == '.I'):\n",
    "        qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cacmQuery[i].strip()] = cacmQuery[i+1].strip()\n",
    "    notTheFirst = True\n",
    "qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "qDataFrame.set_index('.I', inplace=True)\n",
    "qDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qDataFrame.to_csv('../../cacmData/cacmQueryCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte qrels.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getRles(path):\n",
    "    with open(path, 'r') as f:\n",
    "        global qrlesList\n",
    "        qrlesList = f.read().split('\\n')\n",
    "        return qrlesList\n",
    "\n",
    "qrelsData = getRles(CACMQRELS)\n",
    "qrelsFrame = pd.DataFrame(columns=['.I', 'data'])\n",
    "seriesDict:dict = {'.I':None, 'data':None}\n",
    "seriesData = seriesDict.copy()\n",
    "for i in qrelsData:\n",
    "    try:\n",
    "        element = i.split(' ')\n",
    "        seriesData['.I'] = int(element[0])\n",
    "        seriesData['data'] = int(element[1])\n",
    "        qrelsFrame = qrelsFrame.append(seriesData, ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelsFrame.to_csv('../../cacmData/cacmQRels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.T</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "      <th>.A</th>\n",
       "      <th>.K</th>\n",
       "      <th>.C</th>\n",
       "      <th>.N</th>\n",
       "      <th>.X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preliminary Report-International Algebraic Lan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Perlis, A. J. Samelson,K.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581203 JB March 22, 1978  8:28 PM</td>\n",
       "      <td>100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extraction of Roots by Repeated Subtractions f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Sugai, I.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581202 JB March 22, 1978  8:29 PM</td>\n",
       "      <td>2\\t5\\t2 2\\t5\\t2 2\\t5\\t2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Techniques Department on Matrix Program Schemes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Friedman, M. D.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581201 JB March 22, 1978  8:30 PM</td>\n",
       "      <td>3\\t5\\t3 3\\t5\\t3 3\\t5\\t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glossary of Computer Engineering and Programmi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581103 JB March 22, 1978  8:32 PM</td>\n",
       "      <td>4\\t5\\t4 4\\t5\\t4 4\\t5\\t4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Two Square-Root Approximations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>Wadey, W. G.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581102 JB March 22, 1978  8:33 PM</td>\n",
       "      <td>5\\t5\\t5 5\\t5\\t5 5\\t5\\t5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   .T   .W  \\\n",
       ".I                                                           \n",
       "1   Preliminary Report-International Algebraic Lan...  NaN   \n",
       "2   Extraction of Roots by Repeated Subtractions f...  NaN   \n",
       "3     Techniques Department on Matrix Program Schemes  NaN   \n",
       "4   Glossary of Computer Engineering and Programmi...  NaN   \n",
       "5                      Two Square-Root Approximations  NaN   \n",
       "\n",
       "                     .B                         .A   .K   .C  \\\n",
       ".I                                                             \n",
       "1   CACM December, 1958  Perlis, A. J. Samelson,K.  NaN  NaN   \n",
       "2   CACM December, 1958                  Sugai, I.  NaN  NaN   \n",
       "3   CACM December, 1958            Friedman, M. D.  NaN  NaN   \n",
       "4   CACM November, 1958                        NaN  NaN  NaN   \n",
       "5   CACM November, 1958               Wadey, W. G.  NaN  NaN   \n",
       "\n",
       "                                     .N  \\\n",
       ".I                                        \n",
       "1   CA581203 JB March 22, 1978  8:28 PM   \n",
       "2   CA581202 JB March 22, 1978  8:29 PM   \n",
       "3   CA581201 JB March 22, 1978  8:30 PM   \n",
       "4   CA581103 JB March 22, 1978  8:32 PM   \n",
       "5   CA581102 JB March 22, 1978  8:33 PM   \n",
       "\n",
       "                                                   .X  \n",
       ".I                                                     \n",
       "1   100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...  \n",
       "2                             2\\t5\\t2 2\\t5\\t2 2\\t5\\t2  \n",
       "3                             3\\t5\\t3 3\\t5\\t3 3\\t5\\t3  \n",
       "4                             4\\t5\\t4 4\\t5\\t4 4\\t5\\t4  \n",
       "5                             5\\t5\\t5 5\\t5\\t5 5\\t5\\t5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df:pd.DataFrame = pd.read_csv('../../cacmData/cacmCsv.csv', index_col='.I')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3203\n",
      "True        1\n",
      "Name: .T, dtype: int64\n",
      "\n",
      "True     1617\n",
      "False    1587\n",
      "Name: .W, dtype: int64\n",
      "\n",
      "False    3120\n",
      "True       84\n",
      "Name: .A, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[:,'.T'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.W'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.A'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean wrong values in .N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = df.loc[:,'.N'].to_list()\n",
    "import re\n",
    "lis = [s.replace(',',' ') for s in lis]\n",
    "ids = []\n",
    "\n",
    "\n",
    "pattern = r'[A-Z][a-z]+ +[0-9][0-9]? +[0-9]{4} +[0-9][0-9]?:[0-9][0-9]? +(PM|AM)'\n",
    "for i in range(0,len(lis)):\n",
    "    if re.search(pattern, lis[i]) == None:\n",
    "        ids.append(i)\n",
    "\n",
    "\n",
    "removePattern = r'CA[0-9]* ?[A-Z]{2} +[A-Z][a-z]+ +[0-9][0-9]? +[0-9]{4}'\n",
    "for i in ids:\n",
    "    lis[i] = re.findall(removePattern, lis[i])[0]\n",
    "\n",
    "df.loc[:, '.N'] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../cacmData/cacmDataCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Numbers to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import re\n",
    "reg = r'([0-9]+)'\n",
    "\n",
    "def isFLoat(strNum):\n",
    "    try:\n",
    "        float(strNum)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def converteNumbers(text):\n",
    "    tempText = text.split()\n",
    "    newText = []\n",
    "    for word in tempText:\n",
    "        tempList = re.split(reg,word)\n",
    "        for miniWord in tempList:\n",
    "            if miniWord.isdigit() or isFLoat(miniWord):\n",
    "                temp = p.number_to_words(miniWord)\n",
    "                newText.append(removePunctuation(temp))\n",
    "            else:\n",
    "                newText.append(miniWord)        \n",
    "    tempText = ' '.join(newText)\n",
    "    return tempText\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "def removePunctuation(text):\n",
    "    global translator\n",
    "    return text.translate(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### remove whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWhiteSpace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def removeStopWords(text):\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    wt = word_tokenize(text)\n",
    "    filteredText = [word for word in wt if word not in sw]\n",
    "    return ' '.join(filteredText)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemWords(text):\n",
    "    global stemmer\n",
    "    wt = word_tokenize(text)\n",
    "    stems = []\n",
    "    for word in wt:\n",
    "        temp = stemmer.stem(word)\n",
    "        # if not temp == word:\n",
    "        #     temp = correctWords(temp)\n",
    "        stems.append(temp)\n",
    "    return ' '.join(stems)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag, defaultdict\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lemmatizeWords(text):\n",
    "    # wt = word_tokenize(text)\n",
    "    # lemmas = [lemmatizer.lemmatize(word, pos='a') for word in wt]\n",
    "    # return ' '.join(lemmas)\n",
    "    # return text\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemmas = [lmtzr.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens) ]\n",
    "    return ' '.join(lemmas)\n",
    "lemmatizeWords('hard\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "correct_words = words.words()\n",
    "incorrectWords = '''preliminari'''.split()\n",
    "result = []\n",
    "def correctWords(text):\n",
    "    for word in text:\n",
    "        try:\n",
    "            temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                                      set(ngrams(w, 2))),w)\n",
    "                                      for w in correct_words if w[0] == word[0]]\n",
    "            result.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        except:\n",
    "            pass\n",
    "    return ' '.join(result)\n",
    "# correctWords(incorrectWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cacm process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "caRegex = r'CA[0-9a-z]* ?[A-Z]+ '\n",
    "def TitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    # tempText = correctWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def abstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    # tempText = correctWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def publicationPreProcesse(p):\n",
    "    tempText = p.replace('CACM ','')\n",
    "    return pd.to_datetime(tempText)\n",
    "\n",
    "def authorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word.replace(',','')))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "def kPreProcesse(k):\n",
    "    tempText = toLower(k)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    # tempText = correctWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def cPreProcesse(c):\n",
    "    tempText = removeWhiteSpace(c)\n",
    "    return tempText\n",
    "\n",
    "def infoPreProcesse(i):\n",
    "    # tempText = toLower(i)\n",
    "    # tempText = converteNumbers(tempText)\n",
    "    # tempText = removePunctuation(tempText)\n",
    "    # remove the (CA581202 JB) ... and converte the rest to date type\n",
    "    # tempText = re.sub(caRegex, '', i)\n",
    "    # tempText = pd.to_datetime(tempText)\n",
    "    #tempText = removeWhiteSpace(tempText)\n",
    "    # tempText = removeStopWords(tempText)\n",
    "    # tempText = stemWords(tempText)\n",
    "    # tempText = lemmatizeWords(tempText)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocessedData(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            templist = []\n",
    "            tempC = tempB = tempI = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                templist.append(TitlePreProcesse(dataFrame.loc[i, '.T']))\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                templist.append(abstractPreProcesse(dataFrame.loc[i, '.W']))\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                templist.append(authorPreProcesse(dataFrame.loc[i, '.A']))\n",
    "            # if not dataFrame.loc[i, '.K'] == '':\n",
    "            #     templist.append(kPreProcesse(dataFrame.loc[i, '.K']))\n",
    "            # if not dataFrame.loc[i, '.C'] == '':\n",
    "            #     tempC = cPreProcesse(dataFrame.loc[i, '.C'])\n",
    "\n",
    "\n",
    "            seriesData['.I'] = i\n",
    "            seriesData['data'] = ' '.join(templist)\n",
    "            seriesData['.B'] = tempB\n",
    "            # seriesData['.C'] = tempC\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.set_index('.I', inplace=True)\n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.T</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "      <th>.A</th>\n",
       "      <th>.K</th>\n",
       "      <th>.C</th>\n",
       "      <th>.N</th>\n",
       "      <th>.X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preliminary Report-International Algebraic Lan...</td>\n",
       "      <td></td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Perlis, A. J. Samelson,K.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CA581203 JB March 22  1978  8:28 PM</td>\n",
       "      <td>100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extraction of Roots by Repeated Subtractions f...</td>\n",
       "      <td></td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Sugai, I.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CA581202 JB March 22  1978  8:29 PM</td>\n",
       "      <td>2\\t5\\t2 2\\t5\\t2 2\\t5\\t2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Techniques Department on Matrix Program Schemes</td>\n",
       "      <td></td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Friedman, M. D.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CA581201 JB March 22  1978  8:30 PM</td>\n",
       "      <td>3\\t5\\t3 3\\t5\\t3 3\\t5\\t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glossary of Computer Engineering and Programmi...</td>\n",
       "      <td></td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CA581103 JB March 22  1978  8:32 PM</td>\n",
       "      <td>4\\t5\\t4 4\\t5\\t4 4\\t5\\t4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Two Square-Root Approximations</td>\n",
       "      <td></td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>Wadey, W. G.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CA581102 JB March 22  1978  8:33 PM</td>\n",
       "      <td>5\\t5\\t5 5\\t5\\t5 5\\t5\\t5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   .T .W                   .B  \\\n",
       ".I                                                                              \n",
       "1   Preliminary Report-International Algebraic Lan...     CACM December, 1958   \n",
       "2   Extraction of Roots by Repeated Subtractions f...     CACM December, 1958   \n",
       "3     Techniques Department on Matrix Program Schemes     CACM December, 1958   \n",
       "4   Glossary of Computer Engineering and Programmi...     CACM November, 1958   \n",
       "5                      Two Square-Root Approximations     CACM November, 1958   \n",
       "\n",
       "                           .A .K .C                                   .N  \\\n",
       ".I                                                                         \n",
       "1   Perlis, A. J. Samelson,K.        CA581203 JB March 22  1978  8:28 PM   \n",
       "2                   Sugai, I.        CA581202 JB March 22  1978  8:29 PM   \n",
       "3             Friedman, M. D.        CA581201 JB March 22  1978  8:30 PM   \n",
       "4                                    CA581103 JB March 22  1978  8:32 PM   \n",
       "5                Wadey, W. G.        CA581102 JB March 22  1978  8:33 PM   \n",
       "\n",
       "                                                   .X  \n",
       ".I                                                     \n",
       "1   100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...  \n",
       "2                             2\\t5\\t2 2\\t5\\t2 2\\t5\\t2  \n",
       "3                             3\\t5\\t3 3\\t5\\t3 3\\t5\\t3  \n",
       "4                             4\\t5\\t4 4\\t5\\t4 4\\t5\\t4  \n",
       "5                             5\\t5\\t5 5\\t5\\t5 5\\t5\\t5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cacmData/cacmDataCleaned.csv')\n",
    "data.set_index('.I', inplace=True)\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>preliminari report intern algebra languag perl...</td>\n",
       "      <td>1958-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>extract root repeat subtract digit comput sugai</td>\n",
       "      <td>1958-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>techniqu depart matrix program scheme friedman</td>\n",
       "      <td>1958-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>glossari comput engin program terminolog</td>\n",
       "      <td>1958-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>two squar root approxim wadey</td>\n",
       "      <td>1958-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data         .B\n",
       ".I                                                               \n",
       "1.0  preliminari report intern algebra languag perl... 1958-12-01\n",
       "2.0    extract root repeat subtract digit comput sugai 1958-12-01\n",
       "3.0     techniqu depart matrix program scheme friedman 1958-12-01\n",
       "4.0           glossari comput engin program terminolog 1958-11-01\n",
       "5.0                      two squar root approxim wadey 1958-11-01"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedDAta = preprocessedData(data)\n",
    "processedDAta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta.to_csv('../../cacmData/cacmDataPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "infoRegex1 = r'^( ?[0-9]+\\.)' \n",
    "inforRegex2 = re.compile('\\(.*\\)')\n",
    "\n",
    "\n",
    "def qAbstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    # tempText = correctWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def qAuthorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word.replace(',','')))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "def qInfoPreProcesse(i):\n",
    "    # tempText = re.sub(infoRegex1, '', i)\n",
    "    # tempText = ' '.join(inforRegex2.findall(tempText))\n",
    "    # tempText = qAbstractPreProcesse(tempText)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocesseQuery(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame(columns=['.I','data'])\n",
    "    seriesDict:dict = {'.I':None, 'data':None} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            templist = []\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                templist.append(qAbstractPreProcesse(dataFrame.loc[i, '.W']))\n",
    "            # if not dataFrame.loc[i, '.A'] == '':\n",
    "            #     templist.append(qAuthorPreProcesse(dataFrame.loc[i, '.A']))\n",
    "            # if not dataFrame.loc[i, '.N'] == '':\n",
    "            #     templist.append(qInfoPreProcesse(dataFrame.loc[i, '.N']))\n",
    "\n",
    "            seriesData['.I'] = i\n",
    "            seriesData['data'] = ' '.join(templist)\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.set_index('.I', inplace=True)\n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.W</th>\n",
       "      <th>.A</th>\n",
       "      <th>.N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What articles exist which deal with TSS (Time ...</td>\n",
       "      <td></td>\n",
       "      <td>1. Richard Alexander, Comp Serv, Langmuir Lab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am interested in articles written either by ...</td>\n",
       "      <td>Prieve, B. Pooch, U.</td>\n",
       "      <td>2. Richard Alexander, Comp Serv, Langmuir Lab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intermediate languages used in construction of...</td>\n",
       "      <td></td>\n",
       "      <td>3. Donna Bergmark, Comp Serv, Uris Hall (inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm interested in mechanisms for communicating...</td>\n",
       "      <td></td>\n",
       "      <td>4. Pavel Curtis (comm mech for disjoint proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'd like papers on design and implementation o...</td>\n",
       "      <td></td>\n",
       "      <td>5. Pavel Curtis (editing interfaces)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   .W                    .A  \\\n",
       ".I                                                                            \n",
       "1   What articles exist which deal with TSS (Time ...                         \n",
       "2   I am interested in articles written either by ...  Prieve, B. Pooch, U.   \n",
       "3   Intermediate languages used in construction of...                         \n",
       "4   I'm interested in mechanisms for communicating...                         \n",
       "5   I'd like papers on design and implementation o...                         \n",
       "\n",
       "                                                   .N  \n",
       ".I                                                     \n",
       "1   1. Richard Alexander, Comp Serv, Langmuir Lab ...  \n",
       "2   2. Richard Alexander, Comp Serv, Langmuir Lab ...  \n",
       "3   3. Donna Bergmark, Comp Serv, Uris Hall (inter...  \n",
       "4   4. Pavel Curtis (comm mech for disjoint proces...  \n",
       "5                5. Pavel Curtis (editing interfaces)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "querydf = pd.read_csv('../../cacmData/cacmQueryCsv.csv')\n",
    "querydf.set_index('.I', inplace=True)\n",
    "querydf.fillna('', inplace=True)\n",
    "querydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.I</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>articl exist deal tss time share system oper s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interest articl write either priev udo pooch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intermedi languag use construct multi target c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interest mechan commun disjoint process possib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like paper design implement edit interfac wind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data\n",
       ".I                                                   \n",
       "1   articl exist deal tss time share system oper s...\n",
       "2        interest articl write either priev udo pooch\n",
       "3   intermedi languag use construct multi target c...\n",
       "4   interest mechan commun disjoint process possib...\n",
       "5   like paper design implement edit interfac wind..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedQuery = preprocesseQuery(querydf)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.to_csv('../../cacmData/cacmQueryPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    .I                                               data          .B\n",
      "0  1.0  preliminari report intern algebra languag perl...  1958-12-01\n",
      "1  2.0    extract root repeat subtract digit comput sugai  1958-12-01\n",
      "2  3.0     techniqu depart matrix program scheme friedman  1958-12-01\n",
      "3  4.0           glossari comput engin program terminolog  1958-11-01\n",
      "4  5.0                      two squar root approxim wadey  1958-11-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "data = pd.read_csv('../../cacmData/cacmDataPreprocessed.csv')\n",
    "data.fillna('', inplace=True)\n",
    "print(data.head())\n",
    "\n",
    "# with open('../../../cacm/common_words', 'r') as f:\n",
    "#     global commonWords\n",
    "#     commonWords = f.read().split('\\n')  \n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "tfidfTable = tfidf.fit_transform(data['data'])\n",
    "\n",
    "\n",
    "def search(query,n:int):\n",
    "    querytfidf = tfidf.transform([query])\n",
    "    cos = cosine_similarity(tfidfTable, querytfidf) \n",
    "    resultList = cos.argsort(axis=0)[-n:][::-1]\n",
    "    ls = []\n",
    "    ids = []\n",
    "    for i in resultList:\n",
    "        ids.append(data.loc[i,'.I'].to_list()[0])\n",
    "        # print(data.loc[i,'.I'].to_list()[0])\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesPath = '../../cacmData/cacmQueryPreprocessed.csv'\n",
    "queriesData = pd.read_csv(queriesPath)\n",
    "\n",
    "\n",
    "def queryingData(qDataFrame:pd.DataFrame, n):\n",
    "    result = pd.DataFrame()\n",
    "    resultDict:dict = {}\n",
    "    resultDictCopy = resultDict.copy()\n",
    "    for i in qDataFrame.index:\n",
    "        try:\n",
    "            tempList:list = search(qDataFrame.loc[i,'data'], n)\n",
    "            for id in range(1,n+1):\n",
    "                resultDictCopy[str(id)] = tempList[id - 1]\n",
    "            result = result.append(resultDictCopy, ignore_index=True)\n",
    "            resultDictCopy = resultDict.copy()\n",
    "        except:\n",
    "            print(i)\n",
    "            raise\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1938.0</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>2218.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>2371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1183.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>3078.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>2526.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2912.0</td>\n",
       "      <td>598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1134.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>3189.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2939.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>3141.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>2450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2716.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>2629.0</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>3144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7       8       9  \\\n",
       "0  1938.0  1168.0  1071.0  1572.0   971.0  1908.0  2218.0  1410.0  2151.0   \n",
       "1  1183.0  1781.0  1149.0  3078.0   597.0  1651.0  2526.0   282.0  2912.0   \n",
       "2  1134.0  1223.0  1496.0  2652.0   799.0   265.0  1162.0  3189.0  1870.0   \n",
       "3  2939.0  2377.0  2376.0  3128.0  3101.0  3141.0   438.0  1439.0  3103.0   \n",
       "4  2716.0  2321.0  2003.0  3011.0  2105.0  1829.0  2629.0  1272.0  2035.0   \n",
       "\n",
       "       10  \n",
       "0  2371.0  \n",
       "1   598.0  \n",
       "2  1304.0  \n",
       "3  2450.0  \n",
       "4  3144.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queriesResult = queryingData(queriesData, 10)\n",
    "queriesResult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def reSizeLists(l1:list, l2:list):\n",
    "    if len(l1) < len(l2):\n",
    "        l2 = l2[0:len(l1)]\n",
    "    while len(l1) > len(l2):\n",
    "        l1 = l1[0:len(l2)]\n",
    "\n",
    "    return l1, l2, len(l1)\n",
    "\n",
    "\n",
    "def precWithoutOrder(l1:list,l2:list):\n",
    "    return len(set(l1).intersection(set(l2))) / len(l1)\n",
    "\n",
    "\n",
    "def calcPrecisionAtK(resData:pd.DataFrame, qresData: pd.DataFrame):\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "    for i in resData.index:\n",
    "        precisionOnQuery = []\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qresData.loc[qresData['.I'] == i+1, 'data'].to_numpy()\n",
    "        resArray, qresArray, lenth = reSizeLists(resArray, qresArray)\n",
    "        for lenI in range(lenth-1,lenth):\n",
    "            tempRes:list = resArray[0:lenI+1].tolist()\n",
    "            tempQRes:list = qresArray[0:lenI+1].tolist()\n",
    "            precisionOnQuery.append(precision_score(tempQRes, tempRes, average='weighted', zero_division=0))\n",
    "            #\n",
    "            # if i == 0:\n",
    "            #     print(tempRes)\n",
    "            #     print(tempQRes)\n",
    "            #     print(precisionOnQuery)\n",
    "        # precisionOnQuery.append(precision_score(qresArray, resArray, average='weighted', zero_division=0))        \n",
    "        try:\n",
    "            precisionsAtK.append(sum(precisionOnQuery) / len(precisionOnQuery))\n",
    "        except ZeroDivisionError: \n",
    "            precisionsAtK.append(0)\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    # print(precisionAtK)\n",
    "    return precisionAtK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qrelsFrame = pd.read_csv('../../cacmData/cacmQRels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047070312499999996"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPrecisionAtK(queriesResult, qrelsFrame)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ad1a5a807b944b1335f606d031e49130ad1da3a9de40b9fa5d942006ec880ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IRProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
