{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CACM DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACMDATA = '../../../../cacm/cacm.all'\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "IDMarker = re.compile('(\\.I.)')\n",
    "allMarkers = re.compile('(\\.[ITWBACKNX] )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queries info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACMQUERY = '../../../../cacm/query.text'\n",
    "CACMQRELS = '../../../../cacm/qrels.text'\n",
    "import re\n",
    "queryMarkers = re.compile('(\\.[IWAN] )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(PATH, marker):\n",
    "    \"\"\"get the data from the file and split it by pattern\"\"\"\n",
    "    with open(PATH, 'r') as f:\n",
    "        t = f.read().replace('\\n', ' ')\n",
    "        lines = re.split(marker, t)\n",
    "        lines.pop(0)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte CACM.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacmData = getData(CACMDATA, allMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributeCacmData(cacmData):\n",
    "    ''' after doing getdata method on cacm.all this method converte it to dataframe'''\n",
    "    dataFrame = pd.DataFrame(columns=['.I','.T','.W','.B','.A','.K','.C','.N','.X'])\n",
    "    seriesDict:dict = {\n",
    "        '.I': None,\n",
    "        '.T': None,\n",
    "        '.W': None,\n",
    "        '.B': None,\n",
    "        '.K': None,\n",
    "        '.C': None,\n",
    "        '.A': None,\n",
    "        '.N': None,\n",
    "        '.X': None\n",
    "    }\n",
    "    seriesData = seriesDict.copy()\n",
    "    notTheFirst = False\n",
    "    for i in range(0, len(cacmData), 2):\n",
    "        if (notTheFirst and cacmData[i].strip() == '.I'):\n",
    "            dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "            seriesData = seriesDict.copy()\n",
    "\n",
    "        seriesData[cacmData[i].strip()] = cacmData[i+1].strip()\n",
    "        notTheFirst = True\n",
    "    dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "      <th>.A</th>\n",
       "      <th>.K</th>\n",
       "      <th>.C</th>\n",
       "      <th>.N</th>\n",
       "      <th>.X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Preliminary Report-International Algebraic Lan...</td>\n",
       "      <td>None</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Perlis, A. J. Samelson,K.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CA581203 JB March 22, 1978  8:28 PM</td>\n",
       "      <td>100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Extraction of Roots by Repeated Subtractions f...</td>\n",
       "      <td>None</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Sugai, I.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CA581202 JB March 22, 1978  8:29 PM</td>\n",
       "      <td>2\\t5\\t2 2\\t5\\t2 2\\t5\\t2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Techniques Department on Matrix Program Schemes</td>\n",
       "      <td>None</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Friedman, M. D.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CA581201 JB March 22, 1978  8:30 PM</td>\n",
       "      <td>3\\t5\\t3 3\\t5\\t3 3\\t5\\t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Glossary of Computer Engineering and Programmi...</td>\n",
       "      <td>None</td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CA581103 JB March 22, 1978  8:32 PM</td>\n",
       "      <td>4\\t5\\t4 4\\t5\\t4 4\\t5\\t4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Two Square-Root Approximations</td>\n",
       "      <td>None</td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>Wadey, W. G.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CA581102 JB March 22, 1978  8:33 PM</td>\n",
       "      <td>5\\t5\\t5 5\\t5\\t5 5\\t5\\t5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .I                                                 .T    .W  \\\n",
       "0  1  Preliminary Report-International Algebraic Lan...  None   \n",
       "1  2  Extraction of Roots by Repeated Subtractions f...  None   \n",
       "2  3    Techniques Department on Matrix Program Schemes  None   \n",
       "3  4  Glossary of Computer Engineering and Programmi...  None   \n",
       "4  5                     Two Square-Root Approximations  None   \n",
       "\n",
       "                    .B                         .A    .K    .C  \\\n",
       "0  CACM December, 1958  Perlis, A. J. Samelson,K.  None  None   \n",
       "1  CACM December, 1958                  Sugai, I.  None  None   \n",
       "2  CACM December, 1958            Friedman, M. D.  None  None   \n",
       "3  CACM November, 1958                       None  None  None   \n",
       "4  CACM November, 1958               Wadey, W. G.  None  None   \n",
       "\n",
       "                                    .N  \\\n",
       "0  CA581203 JB March 22, 1978  8:28 PM   \n",
       "1  CA581202 JB March 22, 1978  8:29 PM   \n",
       "2  CA581201 JB March 22, 1978  8:30 PM   \n",
       "3  CA581103 JB March 22, 1978  8:32 PM   \n",
       "4  CA581102 JB March 22, 1978  8:33 PM   \n",
       "\n",
       "                                                  .X  \n",
       "0  100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...  \n",
       "1                            2\\t5\\t2 2\\t5\\t2 2\\t5\\t2  \n",
       "2                            3\\t5\\t3 3\\t5\\t3 3\\t5\\t3  \n",
       "3                            4\\t5\\t4 4\\t5\\t4 4\\t5\\t4  \n",
       "4                            5\\t5\\t5 5\\t5\\t5 5\\t5\\t5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacmCsvDis = distributeCacmData(cacmData)\n",
    "cacmCsvDis.head()\n",
    "# .to_csv('../../cacmData/cacmCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte query.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacmQuery = getData(CACMQUERY, queryMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributeCacmQueries(cacmQuery):\n",
    "    ''' after doing getdata method on cacm.qry this method converte it to dataframe'''\n",
    "    qDataFrame = pd.DataFrame(columns=['.I','.T','.W','.A','.N'])\n",
    "    seriesDict:dict = {\n",
    "        '.I': None,\n",
    "        '.T': None,\n",
    "        '.W': None,\n",
    "        '.A': None,\n",
    "        '.N': None\n",
    "    }\n",
    "    seriesData = seriesDict.copy()\n",
    "    notTheFirst = False\n",
    "    for i in range(0, len(cacmQuery), 2):\n",
    "        if (notTheFirst and cacmQuery[i].strip() == '.I'):\n",
    "            qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "            seriesData = seriesDict.copy()\n",
    "\n",
    "        seriesData[cacmQuery[i].strip()] = cacmQuery[i+1].strip()\n",
    "        notTheFirst = True\n",
    "    qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "    return qDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "      <th>.A</th>\n",
       "      <th>.K</th>\n",
       "      <th>.C</th>\n",
       "      <th>.N</th>\n",
       "      <th>.X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>What articles exist which deal with TSS (Time ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1. Richard Alexander, Comp Serv, Langmuir Lab ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>I am interested in articles written either by ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Prieve, B. Pooch, U.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2. Richard Alexander, Comp Serv, Langmuir Lab ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>Intermediate languages used in construction of...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3. Donna Bergmark, Comp Serv, Uris Hall (inter...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>I'm interested in mechanisms for communicating...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4. Pavel Curtis (comm mech for disjoint proces...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>I'd like papers on design and implementation o...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5. Pavel Curtis (editing interfaces)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .I    .T                                                 .W    .B  \\\n",
       "0  1  None  What articles exist which deal with TSS (Time ...  None   \n",
       "1  2  None  I am interested in articles written either by ...  None   \n",
       "2  3  None  Intermediate languages used in construction of...  None   \n",
       "3  4  None  I'm interested in mechanisms for communicating...  None   \n",
       "4  5  None  I'd like papers on design and implementation o...  None   \n",
       "\n",
       "                     .A    .K    .C  \\\n",
       "0                  None  None  None   \n",
       "1  Prieve, B. Pooch, U.  None  None   \n",
       "2                  None  None  None   \n",
       "3                  None  None  None   \n",
       "4                  None  None  None   \n",
       "\n",
       "                                                  .N    .X  \n",
       "0  1. Richard Alexander, Comp Serv, Langmuir Lab ...  None  \n",
       "1  2. Richard Alexander, Comp Serv, Langmuir Lab ...  None  \n",
       "2  3. Donna Bergmark, Comp Serv, Uris Hall (inter...  None  \n",
       "3  4. Pavel Curtis (comm mech for disjoint proces...  None  \n",
       "4               5. Pavel Curtis (editing interfaces)  None  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacmQueryCsvDis = distributeCacmData(cacmQuery)\n",
    "cacmQueryCsvDis.head()\n",
    "# qDataFrame.to_csv('../../cacmData/cacmQueryCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte qrels.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .I  data\n",
       "0  1  1410\n",
       "1  1  1572\n",
       "2  1  1605\n",
       "3  1  2020\n",
       "4  1  2358"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getRles(path):\n",
    "    with open(path, 'r') as f:\n",
    "        global qrlesList\n",
    "        qrlesList = f.read().split('\\n')\n",
    "        return qrlesList\n",
    "\n",
    "qrelsData = getRles(CACMQRELS)\n",
    "qrelsFrame = pd.DataFrame(columns=['.I', 'data'])\n",
    "seriesDict:dict = {'.I':None, 'data':None}\n",
    "seriesData = seriesDict.copy()\n",
    "for i in qrelsData:\n",
    "    try:\n",
    "        element = i.split(' ')\n",
    "        seriesData['.I'] = int(element[0])\n",
    "        seriesData['data'] = int(element[1])\n",
    "        qrelsFrame = qrelsFrame.append(seriesData, ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelsFrame.to_csv('../../cacmData/cacmQRels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.T</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "      <th>.A</th>\n",
       "      <th>.K</th>\n",
       "      <th>.C</th>\n",
       "      <th>.N</th>\n",
       "      <th>.X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preliminary Report-International Algebraic Lan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Perlis, A. J. Samelson,K.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581203 JB March 22, 1978  8:28 PM</td>\n",
       "      <td>100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extraction of Roots by Repeated Subtractions f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Sugai, I.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581202 JB March 22, 1978  8:29 PM</td>\n",
       "      <td>2\\t5\\t2 2\\t5\\t2 2\\t5\\t2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Techniques Department on Matrix Program Schemes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM December, 1958</td>\n",
       "      <td>Friedman, M. D.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581201 JB March 22, 1978  8:30 PM</td>\n",
       "      <td>3\\t5\\t3 3\\t5\\t3 3\\t5\\t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glossary of Computer Engineering and Programmi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581103 JB March 22, 1978  8:32 PM</td>\n",
       "      <td>4\\t5\\t4 4\\t5\\t4 4\\t5\\t4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Two Square-Root Approximations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACM November, 1958</td>\n",
       "      <td>Wadey, W. G.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA581102 JB March 22, 1978  8:33 PM</td>\n",
       "      <td>5\\t5\\t5 5\\t5\\t5 5\\t5\\t5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   .T   .W  \\\n",
       ".I                                                           \n",
       "1   Preliminary Report-International Algebraic Lan...  NaN   \n",
       "2   Extraction of Roots by Repeated Subtractions f...  NaN   \n",
       "3     Techniques Department on Matrix Program Schemes  NaN   \n",
       "4   Glossary of Computer Engineering and Programmi...  NaN   \n",
       "5                      Two Square-Root Approximations  NaN   \n",
       "\n",
       "                     .B                         .A   .K   .C  \\\n",
       ".I                                                             \n",
       "1   CACM December, 1958  Perlis, A. J. Samelson,K.  NaN  NaN   \n",
       "2   CACM December, 1958                  Sugai, I.  NaN  NaN   \n",
       "3   CACM December, 1958            Friedman, M. D.  NaN  NaN   \n",
       "4   CACM November, 1958                        NaN  NaN  NaN   \n",
       "5   CACM November, 1958               Wadey, W. G.  NaN  NaN   \n",
       "\n",
       "                                     .N  \\\n",
       ".I                                        \n",
       "1   CA581203 JB March 22, 1978  8:28 PM   \n",
       "2   CA581202 JB March 22, 1978  8:29 PM   \n",
       "3   CA581201 JB March 22, 1978  8:30 PM   \n",
       "4   CA581103 JB March 22, 1978  8:32 PM   \n",
       "5   CA581102 JB March 22, 1978  8:33 PM   \n",
       "\n",
       "                                                   .X  \n",
       ".I                                                     \n",
       "1   100\\t5\\t1 123\\t5\\t1 164\\t5\\t1 1\\t5\\t1 1\\t5\\t1 ...  \n",
       "2                             2\\t5\\t2 2\\t5\\t2 2\\t5\\t2  \n",
       "3                             3\\t5\\t3 3\\t5\\t3 3\\t5\\t3  \n",
       "4                             4\\t5\\t4 4\\t5\\t4 4\\t5\\t4  \n",
       "5                             5\\t5\\t5 5\\t5\\t5 5\\t5\\t5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df:pd.DataFrame = pd.read_csv('../../cacmData/cacmCsv.csv', index_col='.I')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3203\n",
      "True        1\n",
      "Name: .T, dtype: int64\n",
      "\n",
      "True     1617\n",
      "False    1587\n",
      "Name: .W, dtype: int64\n",
      "\n",
      "False    3120\n",
      "True       84\n",
      "Name: .A, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[:,'.T'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.W'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.A'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean wrong values in .N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = df.loc[:,'.N'].to_list()\n",
    "import re\n",
    "lis = [s.replace(',',' ') for s in lis]\n",
    "ids = []\n",
    "\n",
    "\n",
    "pattern = r'[A-Z][a-z]+ +[0-9][0-9]? +[0-9]{4} +[0-9][0-9]?:[0-9][0-9]? +(PM|AM)'\n",
    "for i in range(0,len(lis)):\n",
    "    if re.search(pattern, lis[i]) == None:\n",
    "        ids.append(i)\n",
    "\n",
    "\n",
    "removePattern = r'CA[0-9]* ?[A-Z]{2} +[A-Z][a-z]+ +[0-9][0-9]? +[0-9]{4}'\n",
    "for i in ids:\n",
    "    lis[i] = re.findall(removePattern, lis[i])[0]\n",
    "\n",
    "df.loc[:, '.N'] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../cacmData/cacmDataCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def toLower(text):\n",
    "    ''' Convert text to lower case'''\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import re\n",
    "reg = r'([0-9]+)'\n",
    "\n",
    "def isFLoat(strNum):\n",
    "    '''converte float number to word'''\n",
    "    try:\n",
    "        float(strNum)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def converteNumbers(text):\n",
    "    ''' Convert texnumbers to words'''\n",
    "    tempText = text.split()\n",
    "    newText = []\n",
    "    for word in tempText:\n",
    "        tempList = re.split(reg,word)\n",
    "        for miniWord in tempList:\n",
    "            if miniWord.isdigit() or isFLoat(miniWord):\n",
    "                temp = p.number_to_words(miniWord)\n",
    "                newText.append(removePunctuation(temp))\n",
    "            else:\n",
    "                newText.append(miniWord)        \n",
    "    tempText = ' '.join(newText)\n",
    "    return tempText\n",
    "\n",
    "################################################################\n",
    "\n",
    "import string\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "def removePunctuation(text):\n",
    "    ''' remove punctuation from text'''\n",
    "    global translator\n",
    "    return text.translate(translator)\n",
    "\n",
    "################################################################\n",
    "\n",
    "def removeWhiteSpace(text):\n",
    "    '''remove whitespace from text'''\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "################################################################\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def removeStopWords(text):\n",
    "    ''' remove stopwords from text'''\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    wt = word_tokenize(text)\n",
    "    filteredText = [word for word in wt if word not in sw]\n",
    "    return ' '.join(filteredText)\n",
    "\n",
    "################################################################\n",
    "\n",
    "import numpy as np\n",
    "def removeOutliers(tokens):\n",
    "    '''remove outliers from wach document'''\n",
    "    listOfTokens = tokens.split()\n",
    "    fdist = FreqDist(word for word in listOfTokens)\n",
    "    fdistKeys = np.array(list(fdist.keys()))\n",
    "    freqOfWords = [fdist.freq(x) for x in fdistKeys]\n",
    "\n",
    "    q1, q3 = np.percentile(freqOfWords, [25, 75])\n",
    "    IQR = q3 - q1\n",
    "    AVG = np.mean(freqOfWords)\n",
    "    AvgRelValue = round(AVG * len(listOfTokens))\n",
    "    Q1RelValue = round(q1* len(listOfTokens))\n",
    "    Q3RelValue = round(q3 * len(listOfTokens))\n",
    "    st = ' '.join(listOfTokens)\n",
    "\n",
    "    for i in range(0,len(freqOfWords)):\n",
    "        if freqOfWords[i] < q1 - 1.5*IQR:\n",
    "            wordRelValue = round(freqOfWords[i] * len(listOfTokens))\n",
    "            sub = Q1RelValue - wordRelValue\n",
    "            word = fdistKeys[i]\n",
    "            stForAppend = (' '+word+' ') * sub\n",
    "            st = st + stForAppend\n",
    "\n",
    "        if freqOfWords[i] > q3 + 1.5*IQR:\n",
    "            wordRelValue = round(freqOfWords[i] * len(listOfTokens))\n",
    "            sub = wordRelValue - Q3RelValue\n",
    "            word = fdistKeys[i]\n",
    "            st = st.replace(word, '', sub)\n",
    "    \n",
    "    return removeWhiteSpace(st)\n",
    "\n",
    "################################################################\n",
    "\n",
    "def addMostFreq(tokens):\n",
    "    '''add words to empty title'''\n",
    "    listOfTokens = tokens.split()\n",
    "    fdist = FreqDist(word for word in listOfTokens)\n",
    "    fdistKeys = np.array(list(fdist.keys()))\n",
    "    freqOfWords = [fdist.freq(x) for x in fdistKeys]\n",
    "\n",
    "    AVG = np.mean(freqOfWords)\n",
    "    stlis = []\n",
    "\n",
    "    for i in range(0,len(freqOfWords)):\n",
    "        if freqOfWords[i] > AVG:\n",
    "            stlis.append(fdistKeys[i])\n",
    "\n",
    "    \n",
    "    return removeWhiteSpace(' '.join(stlis))\n",
    "\n",
    "################################################################\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemWords(text):\n",
    "    ''' stemm words'''\n",
    "    global stemmer\n",
    "    wt = word_tokenize(text)\n",
    "    stems = []\n",
    "    for word in wt:\n",
    "        temp = stemmer.stem(word)\n",
    "        stems.append(temp)\n",
    "    return ' '.join(stems)\n",
    "\n",
    "################################################################\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag, defaultdict\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "def lemmatizeWords(text):\n",
    "    ''' lemmatize words'''\n",
    "    tokens = word_tokenize(text)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemmas = [lmtzr.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens) ]\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "################################################################\n",
    "\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "\n",
    "correct_words = words.words()\n",
    "result = []\n",
    "\n",
    "def correctWords(text):\n",
    "    for word in text.split():\n",
    "        try:\n",
    "            temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                                      set(ngrams(w, 2))),w)\n",
    "                                      for w in correct_words if w[0] == word[0]]\n",
    "            result.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return ' '.join(result)\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cacm process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TitlePreProcesse(t):\n",
    "    '''do preprocess methods on titles'''\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def abstractPreProcesse(a):\n",
    "    '''do preprocess methods on abstract'''\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    tempText = removeOutliers(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def authorPreProcesse(a):\n",
    "    '''do preprocess methods on authors'''\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word))\n",
    "    names = ' '.join(l)\n",
    "\n",
    "    return names\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def publicationPreProcesse(p):\n",
    "    try:\n",
    "        tempText = p.replace('CACM ','')\n",
    "        return pd.to_datetime(tempText)\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def preprocessedCacmData(dataFrame:pd.DataFrame):\n",
    "    '''take pandas dataFrame with coulmns = {.I, .T, .A, .W, .B} which contain Cacm data and preprocess it'''\n",
    "    pdataFrame = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            tempT = tempA = tempW  =tempB = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = TitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = authorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = abstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "\n",
    "\n",
    "\n",
    "            seriesData['.I'] = i+1\n",
    "            seriesData['.T'] = tempT\n",
    "            seriesData['.A'] = tempA\n",
    "            seriesData['.W'] = tempW\n",
    "            seriesData['.B'] = tempB\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.read_csv('../../cacmData/cacmDataCleaned.csv')\n",
    "# data.fillna('', inplace=True)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>preliminari report intern algebra languag</td>\n",
       "      <td>perlis  samelson k</td>\n",
       "      <td></td>\n",
       "      <td>1958-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>extract root repeat subtract digit comput</td>\n",
       "      <td>sugai</td>\n",
       "      <td></td>\n",
       "      <td>1958-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>techniqu depart matrix program scheme</td>\n",
       "      <td>friedman</td>\n",
       "      <td></td>\n",
       "      <td>1958-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>glossari comput engin program terminolog</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1958-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>two squar root approxim</td>\n",
       "      <td>wadey</td>\n",
       "      <td></td>\n",
       "      <td>1958-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                         .T                   .A .W  \\\n",
       "0  1.0  preliminari report intern algebra languag  perlis  samelson k       \n",
       "1  2.0  extract root repeat subtract digit comput               sugai       \n",
       "2  3.0      techniqu depart matrix program scheme            friedman       \n",
       "3  4.0   glossari comput engin program terminolog                           \n",
       "4  5.0                    two squar root approxim               wadey       \n",
       "\n",
       "          .B  \n",
       "0 1958-12-01  \n",
       "1 1958-12-01  \n",
       "2 1958-12-01  \n",
       "3 1958-11-01  \n",
       "4 1958-11-01  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacmCsvDis.fillna('', inplace=True)\n",
    "processedDAta = preprocessedCacmData(cacmCsvDis)\n",
    "processedDAta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta.to_csv('../../cacmData/cacmDataPre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qTitlePreProcesse(t):\n",
    "    '''do preprocess methods on query titles'''\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def qAbstractPreProcesse(a):\n",
    "    '''do preprocess methods on query abstract'''\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    tempText = removeOutliers(tempText)\n",
    "    return tempText\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def qAuthorPreProcesse(a):\n",
    "    '''do preprocess methods on query authors'''\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def preprocesseQuery(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame() \n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            tempT = tempA = tempW  = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = qTitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = qAuthorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = qAbstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "                if dataFrame.loc[i, '.T'] == '':\n",
    "                    tempT = addMostFreq(tempW)\n",
    "                    \n",
    "\n",
    "                \n",
    "            seriesData['.I'] = i+1\n",
    "            seriesData['.T'] = tempT\n",
    "            seriesData['.A'] = tempA\n",
    "            seriesData['.W'] = tempW\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# querydf = pd.read_csv('../../cacmData/cacmQueryCsv.csv')\n",
    "# querydf.set_index('.I', inplace=True)\n",
    "# querydf.fillna('', inplace=True)\n",
    "# querydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>articl exist deal tss time share oper system i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>interest articl write either priev udo pooch</td>\n",
       "      <td>prieve  pooch</td>\n",
       "      <td>interest articl write either priev udo pooch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>intermedi languag use construct multi target c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>commun disjoint process possibl exclus distrib...</td>\n",
       "      <td></td>\n",
       "      <td>commun disjoint process possibl exclus distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>like paper implement edit window manag command...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                                 .T              .A  \\\n",
       "0  1.0                                                                      \n",
       "1  2.0       interest articl write either priev udo pooch  prieve  pooch    \n",
       "2  3.0                                                                      \n",
       "3  4.0  commun disjoint process possibl exclus distrib...                   \n",
       "4  5.0                                                                      \n",
       "\n",
       "                                                  .W  \n",
       "0  articl exist deal tss time share oper system i...  \n",
       "1       interest articl write either priev udo pooch  \n",
       "2  intermedi languag use construct multi target c...  \n",
       "3  commun disjoint process possibl exclus distrib...  \n",
       "4  like paper implement edit window manag command...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacmQueryCsvDis.fillna('', inplace=True)\n",
    "preprocessedQuery = preprocesseQuery(cacmQueryCsvDis)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.to_csv('../../cacmData/cacmQueryPre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "transformer = None\n",
    "tfidfTable  = None\n",
    "def initializeTfidfTable(data: pd.DataFrame):\n",
    "    ''' put cacm data in pipelinethen fit and transform it and return tfidf Table'''\n",
    "    global transformer, tfidfTable\n",
    "    transformer = FeatureUnion([\n",
    "                      ('title_tfidf', \n",
    "                      Pipeline([\n",
    "                        ('extract_field',\n",
    "                                  FunctionTransformer(lambda x: x['.T'], \n",
    "                                                      validate=False)),\n",
    "                                ('tfidf', \n",
    "                                  TfidfVectorizer(norm='l2' ,ngram_range=(1,2)))]))                              \n",
    "                      ,('abstract_tfidf',\n",
    "                     Pipeline([('extract_field',\n",
    "                                FunctionTransformer(lambda x: x['.W'],\n",
    "                                                      validate=False)),\n",
    "                                ('tfidf',\n",
    "                                  TfidfVectorizer(norm='l1',ngram_range=(1,2)))]))\n",
    "                    ,('author_tfidf', \n",
    "                      Pipeline([('extract_field', \n",
    "                                  FunctionTransformer(lambda x: x['.A'], \n",
    "                                                      validate=False)),\n",
    "                                ('tfidf', \n",
    "                                  TfidfVectorizer(norm='l1'))]))\n",
    "    ])\n",
    "    tfidfTable = transformer.fit_transform(data)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def getSimilars(query):\n",
    "    ''' get the most n similar documents'''\n",
    "    global transformer, tfidfTable\n",
    "    querytfidf = transformer.transform(query)\n",
    "\n",
    "    return cosine_similarity(querytfidf,tfidfTable).flatten()\n",
    "    \n",
    "\n",
    "########################################################################\n",
    "\n",
    "def queryingData(qDataFrame:pd.DataFrame,data:pd.DataFrame, n):\n",
    "    ''' search for all queries in the queries file and get the most n similar document .I'''\n",
    "    result = pd.DataFrame()\n",
    "    for i in qDataFrame.index:\n",
    "        try:\n",
    "            resultDict:dict = {}\n",
    "            tempIds:list = getSimilars(pd.DataFrame(qDataFrame.loc[qDataFrame.index == i,:]), n)\n",
    "\n",
    "            tempList = []\n",
    "            for id in tempIds:\n",
    "                tempList.append(data.loc[id,'.I'])\n",
    "\n",
    "            for id in range(1,n+1):\n",
    "                resultDict[str(id)] = tempList[id - 1]\n",
    "            result = result.append(resultDict, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise\n",
    "    return result\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absSub(a,b):\n",
    "    return abs(a-b)\n",
    "\n",
    "def search(qDF:pd.DataFrame,data:pd.DataFrame, n):\n",
    "    ''' search for input and return list of ids of the result'''\n",
    "    try:\n",
    "        resultlis = []\n",
    "        similars = getSimilars(qDF)\n",
    "        \n",
    "        tempIds = similars.argsort(axis=0)[-n:][::-1]\n",
    "\n",
    "        if not qDF.loc[0, '.B'] == '':\n",
    "            tempFrame = pd.DataFrame()\n",
    "            for id in tempIds:\n",
    "                tempFrame = tempFrame.append(data.loc[id,['.I','.B']])\n",
    "\n",
    "            tempFrame.sort_values(by=['.B']\\\n",
    "                ,key=lambda x: absSub(x, pd.to_datetime(qDF.loc[0, '.B']))\\\n",
    "                    , inplace=True)\n",
    "            \n",
    "            return tempFrame.loc[:, '.I'].to_list()\n",
    "\n",
    "        for id in tempIds:\n",
    "            resultlis.append(data.loc[id,'.I'])\n",
    "\n",
    "        return resultlis\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializeTfidfTable(data=processedDAta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def reSizeLists(l1:list, l2:list):\n",
    "    '''resize lists to have the same len'''\n",
    "    if len(l1) < len(l2):\n",
    "        l2 = l2[0:len(l1)]\n",
    "    while len(l1) > len(l2):\n",
    "        l1 = l1[0:len(l2)]\n",
    "\n",
    "    return l1, l2\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def precWithoutOrder(l1:list,l2:list):\n",
    "    ''' calculate precision witout orering'''\n",
    "    try:\n",
    "        return len(set(l1).intersection(set(l2))) / len(l2)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def calcMAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte MAP (average precision on multiple queries)'''\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "\n",
    "    for i in resData.index:\n",
    "        precisionOnQuery = []\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "        for lenI in range(0,len(qresArray)):\n",
    "            tempRes:list = resArray[0:lenI+1].tolist()\n",
    "            tempQRes:list = qresArray[0:lenI+1].tolist()\n",
    "            precisionOnQuery.append(precision_score(tempQRes, tempRes, average='micro'))\n",
    "        \n",
    "        try:\n",
    "            precisionsAtK.append(sum(precisionOnQuery) / len(precisionOnQuery))\n",
    "        except ZeroDivisionError: \n",
    "            precisionsAtK.append(0)\n",
    "\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    return precisionAtK\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def calcAveragePrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte just Average Precision for one query or more'''\n",
    "    precisionsAtK:list = []\n",
    "\n",
    "    for i in resData.index:\n",
    "        precisionOnQuery = []\n",
    "\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "        for lenI in range(0,len(qresArray)):\n",
    "\n",
    "            tempRes:list = resArray[0:lenI+1].tolist()\n",
    "            tempQRes:list = qresArray[0:lenI+1].tolist()\n",
    "            precisionOnQuery.append(precision_score(tempQRes, tempRes, average='micro'))\n",
    "\n",
    "        try:\n",
    "            precisionsAtK.append(sum(precisionOnQuery) / len(precisionOnQuery))\n",
    "        except ZeroDivisionError: \n",
    "            precisionsAtK.append(0)\n",
    "    return precisionsAtK\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def calcPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte just Precision for one query or more'''\n",
    "    precisionsAtK:list = []\n",
    "\n",
    "    for i in resData.index:\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "        precisionsAtK.append(precision_score(qresArray, resArray, average='micro'))\n",
    "\n",
    "    return sum(precisionsAtK) / len(precisionsAtK)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def calcRecallAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte just recall for one query or more'''\n",
    "    recallsAtK:list = []\n",
    "\n",
    "    for i in resData.index:\n",
    "\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "        recallsAtK.append(recall_score(qresArray, resArray, average='micro'))\n",
    "\n",
    "    return sum(recallsAtK) / len(recallsAtK)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def calcMeanReciprocalRank(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "\n",
    "    resultDataFrame = pd.DataFrame(columns=['.I','data', 'rank'])\n",
    "\n",
    "\n",
    "    for row in resData.index:\n",
    "        temp = resData.loc[row].to_list()\n",
    "        ke = []\n",
    "        rank = []\n",
    "        for i in range(0,len(temp)):\n",
    "            ke.append(row + 1)\n",
    "            rank.append(i+1)\n",
    "        lot = zip(ke,temp, rank)\n",
    "        tempdata = pd.DataFrame(lot, columns=['.I','data', 'rank'])\n",
    "\n",
    "        resultDataFrame = resultDataFrame.append(tempdata, ignore_index=True)\n",
    "\n",
    "    \n",
    "    MAX_RANK = 100000\n",
    "\n",
    "    hits = pd.merge(qrelsData, resultDataFrame,\n",
    "        on=[\".I\", \"data\"],\n",
    "        how=\"left\").fillna(MAX_RANK)\n",
    "\n",
    "    mrr = (1 / hits.groupby('.I')['rank'].min()).mean()\n",
    "\n",
    "    return mrr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def calcMAPrecisionAtKOrder(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte MAP (average precision on multiple queries) without order'''\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "\n",
    "    for i in resData.index:\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "        prec = precWithoutOrder(qresArray, resArray)\n",
    "\n",
    "        precisionsAtK.append(prec)\n",
    "\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    return precisionAtK\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cacmQRELAfCl = pd.read_csv('../../cacmData/cacmQRels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precacmon@10 : 0.057692307692307696\n",
      "recall@10 : 0.057692307692307696\n",
      "MAP : 0.0665583028083028\n",
      "MRR : 0.45747350122100117\n"
     ]
    }
   ],
   "source": [
    "n=10\n",
    "dataPD = queryingData(preprocessedQuery, processedDAta, n)\n",
    "precisionAtN = calcPrecisionAtK(dataPD, cacmQRELAfCl)\n",
    "recallAtN = calcRecallAtK(dataPD, cacmQRELAfCl)\n",
    "meanAveragePrecision = calcMAPrecisionAtK(dataPD, cacmQRELAfCl)\n",
    "meanReciprocalRank = calcMeanReciprocalRank(dataPD, cacmQRELAfCl)\n",
    "\n",
    "print(f'precacmon@{n} : {precisionAtN}')\n",
    "print(f'recall@{n} : {recallAtN}')\n",
    "print(f'MAP : {meanAveragePrecision}')\n",
    "print(f'MRR : {meanReciprocalRank}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocesseSearchInput(dataDic) -> pd.DataFrame:\n",
    "    psi = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "\n",
    "    data = dataDic.get('query')\n",
    "\n",
    "    tempI = 1\n",
    "    tempW = qAbstractPreProcesse(data)\n",
    "    tempT = addMostFreq(tempW)\n",
    "    tempA = ''\n",
    "    try:\n",
    "        tempB = pd.to_datetime(dataDic.get('date'))\n",
    "    except:\n",
    "        tempB = ''\n",
    "\n",
    "    seriesDict['.I'] = tempI\n",
    "    seriesDict['.T'] = tempT\n",
    "    seriesDict['.A'] = tempA\n",
    "    seriesDict['.W'] = tempW\n",
    "    seriesDict['.B'] = tempB\n",
    "   \n",
    "    psi = psi.append(seriesDict, ignore_index=True)\n",
    "    psi.fillna('', inplace=True)\n",
    "\n",
    "    return psi\n",
    "\n",
    "def resultToDict(resultDict, resultIds):\n",
    "    for i in range(0,len(resultIds)):\n",
    "        temp = processedDAta.loc[processedDAta['.I'] == resultIds[i],\\\n",
    "             ['.T', '.A', '.W', '.B']].to_dict()\n",
    "\n",
    "        tk = list(temp.keys())\n",
    "        for sk in tk:\n",
    "            try:\n",
    "                k = list(temp[sk].keys())\n",
    "                temp[sk] = temp[sk][k[0]]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        resultDict['reslutDictionary']['result'][i] = temp\n",
    "\n",
    "    return resultDict\n",
    "\n",
    "    \n",
    "def searchInput(data):\n",
    "    dataPD: pd.DataFrame = preprocesseSearchInput(data)\n",
    "    resultIds = search(dataPD, processedDAta, data.get('n'))\n",
    "    resultDict = {\n",
    "        'reslutDictionary':{\n",
    "            'result':{},\n",
    "        }\n",
    "    }\n",
    "    return resultToDict(resultDict, resultIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reslutDictionary': {'result': {0: {'.T': 'subroutin assembl',\n",
       "    '.A': 'samet ',\n",
       "    '.W': 'descript give assembl system requir one pas maintain tabl inform subroutin librari',\n",
       "    '.B': Timestamp('1965-01-01 00:00:00')},\n",
       "   1: {'.T': 'american standard ifip icc vocabulari compar',\n",
       "    '.A': 'traub ',\n",
       "    '.W': 'propos american standard ifip icc vocabulari term use inform process analyz compar',\n",
       "    '.B': Timestamp('1965-06-01 00:00:00')},\n",
       "   2: {'.T': 'convent use symbol prepar flowchart inform process system standard work paper',\n",
       "    '.A': '',\n",
       "    '.W': 'paper intend outlin variou consid inform process system convent appli use appear propos american standard flowchart symbol per se',\n",
       "    '.B': Timestamp('1965-07-01 00:00:00')},\n",
       "   3: {'.T': 'protect inform process util',\n",
       "    '.A': 'graham ',\n",
       "    '.W': 'critic design process util permit flexibl share user inform privaci one solut problem discus',\n",
       "    '.B': Timestamp('1968-05-01 00:00:00')},\n",
       "   4: {'.T': 'perform system use data transmiss transfer rate inform bit asa tutori standard',\n",
       "    '.A': '',\n",
       "    '.W': 'thruput characterist system perform discuss discus includ pertin aspect transfer determin transfer bit trib residu error standard measur condit paper also present orderli arrang characterist paramet affect inform thruput exampl procedur determin thruput term trib conclud perform characterist involv inform rate best express trib conjunct residu error rate',\n",
       "    '.B': Timestamp('1965-05-01 00:00:00')},\n",
       "   5: {'.T': 'file organ consecut retriev properti',\n",
       "    '.A': 'ghosh ',\n",
       "    '.W': 'import relat queri set record set exist enabl design inform system minim search time redund storag import theorem prove paper condit consecut properti exist remain invari establish outlin design inform retriev system base consecut retriev properti also discuss',\n",
       "    '.B': Timestamp('1972-09-01 00:00:00')},\n",
       "   6: {'.T': 'system busi autom sba program languag',\n",
       "    '.A': 'zloof  jong ',\n",
       "    '.W': 'system busi autom sba system within expert nonprogramm describ execut comput user sba view applic manipul inform two dimension pictur tabl busi form report display termin gradual autom applic give exampl system manual manipul inform queri exampl databas languag subset sba program languag',\n",
       "    '.B': Timestamp('1977-06-01 00:00:00')},\n",
       "   7: {'.T': 'code isomorph',\n",
       "    '.A': 'lynch ',\n",
       "    '.W': 'code extern symbol intern comput sometim carri way relev inform properti preserv form much easili deal case point present',\n",
       "    '.B': Timestamp('1960-02-01 00:00:00')},\n",
       "   8: {'.T': 'report propos american standard flowchart symbol inform process',\n",
       "    '.A': 'rossheim ',\n",
       "    '.W': 'paper present essenti content flowchart symbol inform process first propos prepar subcommitte x three six problem descript analysi american standard associ asa',\n",
       "    '.B': Timestamp('1963-10-01 00:00:00')},\n",
       "   9: {'.T': 'note confin problem',\n",
       "    '.A': 'lampson ',\n",
       "    '.W': 'note explor confin execut transmit program except caller set exampl attempt stake boundari problem necessari condit solut state inform justifi',\n",
       "    '.B': Timestamp('1973-10-01 00:00:00')}}}}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"query\":\"information\",\n",
    "    \"n\":10,\n",
    "    \"date\":\"\"\n",
    "}\n",
    "searchInput(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reslutDictionary': {'result': {0: {'.T': 'american standard ifip icc vocabulari compar',\n",
       "    '.A': 'traub ',\n",
       "    '.W': 'propos american standard ifip icc vocabulari term use inform process analyz compar',\n",
       "    '.B': Timestamp('1965-06-01 00:00:00')},\n",
       "   1: {'.T': 'convent use symbol prepar flowchart inform process system standard work paper',\n",
       "    '.A': '',\n",
       "    '.W': 'paper intend outlin variou consid inform process system convent appli use appear propos american standard flowchart symbol per se',\n",
       "    '.B': Timestamp('1965-07-01 00:00:00')},\n",
       "   2: {'.T': 'perform system use data transmiss transfer rate inform bit asa tutori standard',\n",
       "    '.A': '',\n",
       "    '.W': 'thruput characterist system perform discuss discus includ pertin aspect transfer determin transfer bit trib residu error standard measur condit paper also present orderli arrang characterist paramet affect inform thruput exampl procedur determin thruput term trib conclud perform characterist involv inform rate best express trib conjunct residu error rate',\n",
       "    '.B': Timestamp('1965-05-01 00:00:00')},\n",
       "   3: {'.T': 'subroutin assembl',\n",
       "    '.A': 'samet ',\n",
       "    '.W': 'descript give assembl system requir one pas maintain tabl inform subroutin librari',\n",
       "    '.B': Timestamp('1965-01-01 00:00:00')},\n",
       "   4: {'.T': 'report propos american standard flowchart symbol inform process',\n",
       "    '.A': 'rossheim ',\n",
       "    '.W': 'paper present essenti content flowchart symbol inform process first propos prepar subcommitte x three six problem descript analysi american standard associ asa',\n",
       "    '.B': Timestamp('1963-10-01 00:00:00')},\n",
       "   5: {'.T': 'protect inform process util',\n",
       "    '.A': 'graham ',\n",
       "    '.W': 'critic design process util permit flexibl share user inform privaci one solut problem discus',\n",
       "    '.B': Timestamp('1968-05-01 00:00:00')},\n",
       "   6: {'.T': 'code isomorph',\n",
       "    '.A': 'lynch ',\n",
       "    '.W': 'code extern symbol intern comput sometim carri way relev inform properti preserv form much easili deal case point present',\n",
       "    '.B': Timestamp('1960-02-01 00:00:00')},\n",
       "   7: {'.T': 'file organ consecut retriev properti',\n",
       "    '.A': 'ghosh ',\n",
       "    '.W': 'import relat queri set record set exist enabl design inform system minim search time redund storag import theorem prove paper condit consecut properti exist remain invari establish outlin design inform retriev system base consecut retriev properti also discuss',\n",
       "    '.B': Timestamp('1972-09-01 00:00:00')},\n",
       "   8: {'.T': 'note confin problem',\n",
       "    '.A': 'lampson ',\n",
       "    '.W': 'note explor confin execut transmit program except caller set exampl attempt stake boundari problem necessari condit solut state inform justifi',\n",
       "    '.B': Timestamp('1973-10-01 00:00:00')},\n",
       "   9: {'.T': 'system busi autom sba program languag',\n",
       "    '.A': 'zloof  jong ',\n",
       "    '.W': 'system busi autom sba system within expert nonprogramm describ execut comput user sba view applic manipul inform two dimension pictur tabl busi form report display termin gradual autom applic give exampl system manual manipul inform queri exampl databas languag subset sba program languag',\n",
       "    '.B': Timestamp('1977-06-01 00:00:00')}}}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"query\":\"information\",\n",
    "    \"n\":10,\n",
    "    \"date\":\"1965-06-01\"\n",
    "}\n",
    "searchInput(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1958-12-01 00:00:00')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFrame = pd.DataFrame()\n",
    "tempFrame = tempFrame.append(processedDAta.loc[processedDAta['.I'] == 1, :])\n",
    "pd.to_datetime(tempFrame.loc[0, '.B'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ad1a5a807b944b1335f606d031e49130ad1da3a9de40b9fa5d942006ec880ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IRProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
