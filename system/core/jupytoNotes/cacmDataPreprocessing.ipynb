{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import re\n",
    "reg = r'([0-9]+)'\n",
    "\n",
    "def isFLoat(strNum):\n",
    "    try:\n",
    "        float(strNum)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def converteNumbers(text):\n",
    "    tempText = text.split()\n",
    "    newText = []\n",
    "    for word in tempText:\n",
    "        tempList = re.split(reg,word)\n",
    "        for miniWord in tempList:\n",
    "            if miniWord.isdigit() or isFLoat(miniWord):\n",
    "                temp = p.number_to_words(miniWord)\n",
    "                newText.append(removePunctuation(temp))\n",
    "            else:\n",
    "                newText.append(miniWord)        \n",
    "    tempText = ' '.join(newText)\n",
    "    return tempText\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "def removePunctuation(text):\n",
    "    global translator\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove WhiteSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWhiteSpace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def removeStopWords(text):\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    wt = word_tokenize(text)\n",
    "    filteredText = [word for word in wt if word not in sw]\n",
    "    return ' '.join(filteredText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemWords(text):\n",
    "    global stemmer\n",
    "    wt = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in wt]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizeWords(text):\n",
    "    wt = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos='v') for word in wt]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CACM.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "caRegex = r'CA[0-9a-z]* ?[A-Z]+ '\n",
    "def TitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def abstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def publicationPreProcesse(p):\n",
    "    # tempText = toLower(p)\n",
    "    # tempText = converteNumbers(tempText)\n",
    "    # tempText = removePunctuation(tempText)\n",
    "    # tempText = removeWhiteSpace(tempText)\n",
    "    # tempText = removeStopWords(tempText)\n",
    "    # tempText = stemWords(tempText)\n",
    "    # tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    # TODO remove cacm word and coverte the rest of the data to dateType \n",
    "    tempText = p.replace('CACM ','')\n",
    "    return pd.to_datetime(tempText)\n",
    "\n",
    "def authorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    # tempText = converteNumbers(tempText)\n",
    "    \n",
    "    # TODO take the first wordbefore ,\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word.replace(',','')))\n",
    "    names = ' '.join(l)\n",
    "\n",
    "    # tempText = removePunctuation(tempText)\n",
    "    \n",
    "    # tempText = removeWhiteSpace(lis[0])\n",
    "    \n",
    "    # tempText = removeStopWords(tempText)\n",
    "    # tempText = stemWords(tempText)\n",
    "    # tempText = lemmatizeWords(tempText)\n",
    "    return names\n",
    "\n",
    "def kPreProcesse(k):\n",
    "    tempText = toLower(k)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def cPreProcesse(c):\n",
    "    # tempText = toLower(c)\n",
    "    # tempText = converteNumbers(tempText)\n",
    "    # tempText = removePunctuation(tempText)\n",
    "    tempText = removeWhiteSpace(c)\n",
    "    # tempText = removeStopWords(tempText)\n",
    "    # tempText = stemWords(tempText)\n",
    "    # tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def infoPreProcesse(i):\n",
    "    # tempText = toLower(i)\n",
    "    # tempText = converteNumbers(tempText)\n",
    "    # tempText = removePunctuation(tempText)\n",
    "    #TODO remove the (CA581202 JB) ... and converte the rest to date type\n",
    "    tempText = re.sub(caRegex, '', i)\n",
    "    tempText = pd.to_datetime(tempText)\n",
    "    #tempText = removeWhiteSpace(tempText)\n",
    "    # tempText = removeStopWords(tempText)\n",
    "    # tempText = stemWords(tempText)\n",
    "    # tempText = lemmatizeWords(tempText)\n",
    "    return tempText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = abstractPreProcesse(\"\"\"\n",
    " Algorithms for parallel computation, and especially comparisons\n",
    "between parallel and sequential algorithms. Mark W. Krentel\n",
    " \"\"\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocessedData(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame(columns=['.I','data','.B','.C','.N','.X'])\n",
    "    seriesDict:dict = {'.I':None, 'data':None, '.B':None, '.C':None,'.N':None, '.X':None} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            templist = []\n",
    "            tempC = tempB = tempI = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                templist.append(TitlePreProcesse(dataFrame.loc[i, '.T']))\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                templist.append(abstractPreProcesse(dataFrame.loc[i, '.W']))\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                templist.append(authorPreProcesse(dataFrame.loc[i, '.A']))\n",
    "            if not dataFrame.loc[i, '.K'] == '':\n",
    "                templist.append(kPreProcesse(dataFrame.loc[i, '.K']))\n",
    "            if not dataFrame.loc[i, '.C'] == '':\n",
    "                tempC = cPreProcesse(dataFrame.loc[i, '.C'])\n",
    "            if not dataFrame.loc[i, '.N'] == '':\n",
    "                tempI = infoPreProcesse(dataFrame.loc[i, '.N'])\n",
    "\n",
    "            seriesData['.I'] = i\n",
    "            seriesData['data'] = ' '.join(templist)\n",
    "            seriesData['.B'] = tempB\n",
    "            seriesData['.C'] = tempC\n",
    "            seriesData['.N'] = tempI\n",
    "            seriesData['.X'] = dataFrame.loc[i,'.X']\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.set_index('.I', inplace=True)\n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cacmData/cacmDataCleanedV1.csv')\n",
    "data.set_index('.I', inplace=True)\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = preprocessedData(data)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = d.loc[-5:, 'data'].tolist()\n",
    "l[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('../../cacmData/cacmDataPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "infoRegex1 = r'^( ?[0-9]+\\.)' \n",
    "inforRegex2 = re.compile('\\(.*\\)')\n",
    "\n",
    "\n",
    "def qAbstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def qAuthorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word.replace(',','')))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "def qInfoPreProcesse(i):\n",
    "    tempText = re.sub(infoRegex1, '', i)\n",
    "    tempText = ' '.join(inforRegex2.findall(tempText))\n",
    "    tempText = qAbstractPreProcesse(tempText)\n",
    "    return tempText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocesseQuery(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame(columns=['.I','data'])\n",
    "    seriesDict:dict = {'.I':None, 'data':None} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            templist = []\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                templist.append(qAbstractPreProcesse(dataFrame.loc[i, '.W']))\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                templist.append(qAuthorPreProcesse(dataFrame.loc[i, '.A']))\n",
    "            if not dataFrame.loc[i, '.N'] == '':\n",
    "                templist.append(qInfoPreProcesse(dataFrame.loc[i, '.N']))\n",
    "\n",
    "            seriesData['.I'] = i\n",
    "            seriesData['data'] = ' '.join(templist)\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.set_index('.I', inplace=True)\n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "querydf = pd.read_csv('../../cacmData/cacmQueryCsv.csv')\n",
    "querydf.set_index('.I', inplace=True)\n",
    "querydf.fillna('', inplace=True)\n",
    "querydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery = preprocesseQuery(querydf)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.loc[0:1, 'data'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.to_csv('../../cacmData/cacmQueryPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ad1a5a807b944b1335f606d031e49130ad1da3a9de40b9fa5d942006ec880ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IRProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
