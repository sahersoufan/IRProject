{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CISIDATA = '../../../../CISI/CISI.ALL'\n",
    "import re\n",
    "IDMarker = re.compile('(\\.I.)')\n",
    "allMarkers = re.compile('(\\.[ITABWX] )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queries info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CISIQUERY = '../../../../CISI/CISI.QRY'\n",
    "CISIQRELS = '../../../../CISI/CISI.REL'\n",
    "import re\n",
    "queryMarkers = re.compile('(\\.[ITAWB] )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(PATH, marker):\n",
    "    \"\"\"get the data from the file and split it by ID\"\"\"\n",
    "    with open(PATH, 'r') as f:\n",
    "        t = f.read().replace('\\n', ' ')\n",
    "        lines = re.split(marker, t)\n",
    "        lines.pop(0)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte CISI.ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisiData = getData(CISIDATA, allMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFrame = pd.DataFrame(columns=['.I','.T','.A','.B','.W','.X'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.A': None,\n",
    "    '.B': None,\n",
    "    '.W': None,\n",
    "    '.X': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cisiData), 2):\n",
    "    if (notTheFirst and cisiData[i].strip() == '.I'):\n",
    "        dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cisiData[i].strip()] = cisiData[i+1].strip()\n",
    "    notTheFirst = True\n",
    "dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.to_csv('../../cisiData/cisiCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte query.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisiQuery = getData(CISIQUERY, queryMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qDataFrame = pd.DataFrame(columns=['.I','.T','.A','.W','.B'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.A': None,\n",
    "    '.W': None,\n",
    "    '.B': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cisiQuery), 2):\n",
    "    if (notTheFirst and cisiQuery[i].strip() == '.I'):\n",
    "        qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cisiQuery[i].strip()] = cisiQuery[i+1].strip()\n",
    "    notTheFirst = True\n",
    "qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "qDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qDataFrame.to_csv('../../cisiData/cisiQueryCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte qrels.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getRles(path):\n",
    "    with open(path, 'r') as f:\n",
    "        global qrlesList\n",
    "        qrlesList = f.read().split('\\n')\n",
    "        return qrlesList\n",
    "\n",
    "qrelsData = getRles(CISIQRELS)\n",
    "qrelsFrame = pd.DataFrame(columns=['.I', 'data'])\n",
    "seriesDict:dict = {'.I':None, 'data':None}\n",
    "seriesData = seriesDict.copy()\n",
    "for i in qrelsData:\n",
    "    try:\n",
    "        element = i.split()\n",
    "        seriesData['.I'] = int(element[0])\n",
    "        seriesData['data'] = int(element[1])\n",
    "        qrelsFrame = qrelsFrame.append(seriesData, ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelsFrame.to_csv('../../cisiData/cisiQRels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df:pd.DataFrame = pd.read_csv('../../cisiData/cisiCsv.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:,'.T'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.W'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.A'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../cisiData/cisiDataCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numbers to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import re\n",
    "reg = r'([0-9]+)'\n",
    "\n",
    "def isFLoat(strNum):\n",
    "    try:\n",
    "        float(strNum)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def converteNumbers(text):\n",
    "    tempText = text.split()\n",
    "    newText = []\n",
    "    for word in tempText:\n",
    "        tempList = re.split(reg,word)\n",
    "        for miniWord in tempList:\n",
    "            if miniWord.isdigit() or isFLoat(miniWord):\n",
    "                temp = p.number_to_words(miniWord)\n",
    "                newText.append(removePunctuation(temp))\n",
    "            else:\n",
    "                newText.append(miniWord)        \n",
    "    tempText = ' '.join(newText)\n",
    "    return tempText\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "def removePunctuation(text):\n",
    "    global translator\n",
    "    return text.translate(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWhiteSpace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "\n",
    "def removeStopWords(text):\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    wt = word_tokenize(text)\n",
    "    filteredText = [word for word in wt if word not in sw]\n",
    "    return ' '.join(filteredText)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calcFreq(tokens):\n",
    "    listOfTokens = tokens.split()\n",
    "    fdist = FreqDist(word for word in listOfTokens)\n",
    "    fdistKeys = np.array(list(fdist.keys()))\n",
    "    freqOfWords = [fdist.freq(x) for x in fdistKeys]\n",
    "\n",
    "    q1, q3 = np.percentile(freqOfWords, [25, 75])\n",
    "    IQR = q3 - q1\n",
    "    AVG = np.mean(freqOfWords)\n",
    "    AvgRelValue = round(AVG * len(listOfTokens))\n",
    "    Q1RelValue = round(q1* len(listOfTokens))\n",
    "    Q3RelValue = round(q3 * len(listOfTokens))\n",
    "    st = ' '.join(listOfTokens)\n",
    "\n",
    "    for i in range(0,len(freqOfWords)):\n",
    "        if freqOfWords[i] < q1 - 1.5*IQR:\n",
    "            wordRelValue = round(freqOfWords[i] * len(listOfTokens))\n",
    "            sub = Q1RelValue - wordRelValue\n",
    "            word = fdistKeys[i]\n",
    "            stForAppend = (' '+word+' ') * sub\n",
    "            st = st + stForAppend\n",
    "\n",
    "        if freqOfWords[i] > q3 + 1.5*IQR:\n",
    "            wordRelValue = round(freqOfWords[i] * len(listOfTokens))\n",
    "            sub = wordRelValue - Q3RelValue\n",
    "            word = fdistKeys[i]\n",
    "            st = st.replace(word, '', sub)\n",
    "    \n",
    "    return removeWhiteSpace(st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = '''note pseudo mathemat relev taube recent number articl book report deal inform system e document retriev system advanc doctrin system evalu term degre percentag relev provid although seem littl agreement relev mean doubt quantifi nevertheless grow agreement fix formal relationship exist relev recal perform system thu find literatur frankli subject notion relev report individu user equat curv mathemat formul presum provid numer measur recal relev characterist inform system phenomenon shift back forth admittedli subject non mathemat term equat term give mathemat valu mathemat definit ancient parallel discus probabl one cours legisl mean term depend alic point master user term hand use singl term document cover two distinct mean especi usag design secur accept doctrin attribut mathemat valid repres seriou situat mere careless ambigu'''\n",
    "qt = '''problem concern make descript titl difficulti involv automat retriev articl approxim titl usual relev content articl titl'''\n",
    "stest = 'saher fatima fatima fatima fatima fatima may may may may may may moh moh moh moh moh '\n",
    "calcFreq(stest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fill query Title with the most freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def addMostFreq(tokens):\n",
    "    listOfTokens = tokens.split()\n",
    "    fdist = FreqDist(word for word in listOfTokens)\n",
    "    fdistKeys = np.array(list(fdist.keys()))\n",
    "    freqOfWords = [fdist.freq(x) for x in fdistKeys]\n",
    "\n",
    "    AVG = np.mean(freqOfWords)\n",
    "    stlis = []\n",
    "\n",
    "    for i in range(0,len(freqOfWords)):\n",
    "        if freqOfWords[i] >= AVG:\n",
    "            stlis.append(fdistKeys[i])\n",
    "\n",
    "    \n",
    "    return removeWhiteSpace(' '.join(stlis))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def checkOutLiers(lineOfPercent):\n",
    "#     try:\n",
    "#         q1 = np.percentile(lineOfPercent, 25, interpolation='midpoint')\n",
    "#         q3 = np.percentile(lineOfPercent, 75, interpolation='midpoint')\n",
    "#         IQR = q3 - q1\n",
    "#         AVG = np.mean(lineOfPercent)\n",
    "#         lineAfterRemoveOutLiers = []\n",
    "#         for i in lineOfPercent:\n",
    "#             if i < q1 - 1.5*IQR:\n",
    "#                 lineAfterRemoveOutLiers.append(AVG)\n",
    "#             elif i > q3 + 1.5*IQR:\n",
    "#               lineAfterRemoveOutLiers.append(AVG)\n",
    "#             else:\n",
    "#              lineAfterRemoveOutLiers.append(i)\n",
    "\n",
    "#         return lineAfterRemoveOutLiers\n",
    "#     except:\n",
    "#         return lineOfPercent\n",
    "\n",
    "\n",
    "\n",
    "# def checkCoverage(queryTokens) -> list:\n",
    "#     covDoc = []\n",
    "\n",
    "#     qTokens = np.array(queryTokens)\n",
    "#     for doc in wordsFreq:\n",
    "#         WordsList = np.array(list(doc.keys()))\n",
    "#         common = np.intersect1d(qTokens, WordsList)\n",
    "#         freqOfWords = [doc.freq(x) for x in common]\n",
    "#         common = checkOutLiers(freqOfWords)\n",
    "#         try:\n",
    "#             covDoc.append(sum(common))\n",
    "#         except:\n",
    "#             covDoc.append(0)\n",
    "    \n",
    "#     sortedList = np.array(covDoc).argsort(axis=0)[::-1]\n",
    "#     return sortedList\n",
    "\n",
    "# # checkCoverage(queryTokens=['saher', 'fatima', 'man', 'hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemWords(text):\n",
    "    global stemmer\n",
    "    wt = word_tokenize(text)\n",
    "    stems = []\n",
    "    for word in wt:\n",
    "        temp = stemmer.stem(word)\n",
    "        # if not temp == word:\n",
    "        #     temp = correctWords(temp)\n",
    "        stems.append(temp)\n",
    "    return ' '.join(stems)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag, defaultdict\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lemmatizeWords(text):\n",
    "    # wt = word_tokenize(text)\n",
    "    # lemmas = [lemmatizer.lemmatize(word, pos='a') for word in wt]\n",
    "    # return ' '.join(lemmas)\n",
    "    # return text\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemmas = [lmtzr.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens) ]\n",
    "    return ' '.join(lemmas)\n",
    "# lemmatizeWords('hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "correct_words = words.words()\n",
    "incorrectWords = '''preliminari'''.split()\n",
    "result = []\n",
    "def correctWords(text):\n",
    "    for word in text:\n",
    "        try:\n",
    "            temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                                      set(ngrams(w, 2))),w)\n",
    "                                      for w in correct_words if w[0] == word[0]]\n",
    "            result.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        except:\n",
    "            pass\n",
    "    return ' '.join(result)\n",
    "# correctWords(incorrectWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cisi process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def TitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "def abstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    tempText = calcFreq(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "# i didn't do it yet on cisi (converte date to timestamp)\n",
    "def publicationPreProcesse(p): \n",
    "    # tempText = p.replace('cisi ','')\n",
    "    # return pd.to_datetime(tempText)\n",
    "    return p\n",
    "    \n",
    "def authorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word))\n",
    "    names = ' '.join(l)\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocessedData(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            tempT = tempA = tempB = tempW = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = TitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = authorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = abstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "            \n",
    "\n",
    "            seriesData['.I'] = i+1\n",
    "            seriesData['.T'] = tempT\n",
    "            seriesData['.A'] = tempA\n",
    "            seriesData['.B'] = tempB\n",
    "            seriesData['.W'] = tempW\n",
    "            \n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cisiData/cisiDataCleaned.csv', index_col=[0])\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta = preprocessedData(data)\n",
    "processedDAta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta.to_csv('../../cisiData/cisiDataPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def qTitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "def qAbstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    tempText = calcFreq(tempText)\n",
    "    return tempText\n",
    "\n",
    "def qAuthorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "\n",
    "# i didn't do it yet on cisi (converte date to timestamp)\n",
    "def qPublicationPreProcesse(p):\n",
    "    # tempText = p.replace('cisi ','')\n",
    "    # return pd.to_datetime(tempText)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocesseQuery(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame() \n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            templist = []\n",
    "            tempT = tempA = tempW = tempB = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = qTitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = qAuthorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = qAbstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "                if dataFrame.loc[i, '.T'] == '':\n",
    "                    tempT = addMostFreq(tempW)\n",
    "                    \n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = qPublicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "\n",
    "\n",
    "                \n",
    "            seriesData['.I'] = i+1\n",
    "            seriesData['.T'] = tempT\n",
    "            seriesData['.A'] = tempA\n",
    "            seriesData['.W'] = tempW\n",
    "            seriesData['.B'] = tempB\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "querydf = pd.read_csv('../../cisiData/cisiQueryCsv.csv', index_col=[0])\n",
    "querydf.fillna('', inplace=True)\n",
    "querydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery = preprocesseQuery(querydf)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.to_csv('../../cisiData/cisiQueryPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    1460\n",
       "Name: .A, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('../../cisiData/cisiDataPreprocessed.csv', index_col=[0])\n",
    "data1['.A'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.B</th>\n",
       "      <th>.W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>eighteen edit dewey decim classif</td>\n",
       "      <td>comaromi</td>\n",
       "      <td></td>\n",
       "      <td>present studi decim classif publish eight six ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>use make technic librari</td>\n",
       "      <td>slater</td>\n",
       "      <td></td>\n",
       "      <td>report analysi six thousand three hundr four u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>two kind power essay bibliograph control</td>\n",
       "      <td>wilson</td>\n",
       "      <td></td>\n",
       "      <td>relationship organ organ inform inevit enter s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>system analysi univers librari final report re...</td>\n",
       "      <td>buckland</td>\n",
       "      <td></td>\n",
       "      <td>new one thousand nine provok highli stimul exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>librari manag game report research project</td>\n",
       "      <td>brophy</td>\n",
       "      <td></td>\n",
       "      <td>although widespread last decad method number f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                                 .T         .A .B  \\\n",
       "0  1.0                  eighteen edit dewey decim classif  comaromi       \n",
       "1  2.0                           use make technic librari    slater       \n",
       "2  3.0           two kind power essay bibliograph control    wilson       \n",
       "3  4.0  system analysi univers librari final report re...  buckland       \n",
       "4  5.0         librari manag game report research project    brophy       \n",
       "\n",
       "                                                  .W  \n",
       "0  present studi decim classif publish eight six ...  \n",
       "1  report analysi six thousand three hundr four u...  \n",
       "2  relationship organ organ inform inevit enter s...  \n",
       "3  new one thousand nine provok highli stimul exa...  \n",
       "4  although widespread last decad method number f...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cisiData/cisiDataPreprocessed.csv', index_col=[0])\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# this is old cell for build index model with merge coulmns into one coulmn (not work now)\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import  cosine_similarity, linear_kernel\n",
    "\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# tfidfTable = tfidf.fit_transform(data['.W'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1460x77879 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 171911 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "\n",
    "\n",
    "transformer = FeatureUnion([\n",
    "                  ('title_tfidf', \n",
    "                  Pipeline([\n",
    "                    ('extract_field',\n",
    "                              FunctionTransformer(lambda x: x['.T'], \n",
    "                                                  validate=False)),\n",
    "                            ('tfidf', \n",
    "                              TfidfVectorizer(norm='l2' ,ngram_range=(1,2)))]))                              \n",
    "                  ,('abstract_tfidf',\n",
    "                 Pipeline([('extract_field',\n",
    "                            FunctionTransformer(lambda x: x['.W'],\n",
    "                                                  validate=False)),\n",
    "                            ('tfidf',\n",
    "                              TfidfVectorizer(norm='l1',ngram_range=(1,2)))]))\n",
    "                ,('author_tfidf', \n",
    "                  Pipeline([('extract_field', \n",
    "                              FunctionTransformer(lambda x: x['.A'], \n",
    "                                                  validate=False)),\n",
    "                            ('tfidf', \n",
    "                              TfidfVectorizer(norm='l1'))]))\n",
    "])\n",
    "tfidfTable = transformer.fit_transform(data)\n",
    "tfidfTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfTable.toarray()[1000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>problem concern make descript difficulti invol...</td>\n",
       "      <td></td>\n",
       "      <td>problem concern make descript difficulti invol...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>actual pertin data oppos refer entir articl re...</td>\n",
       "      <td></td>\n",
       "      <td>actual pertin data oppos refer entir articl re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>inform scienc give definit possibl</td>\n",
       "      <td></td>\n",
       "      <td>inform scienc give definit possibl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>imag recognit method automat transform print t...</td>\n",
       "      <td></td>\n",
       "      <td>imag recognit method automat transform print t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>special train ordinari research businessmen ne...</td>\n",
       "      <td></td>\n",
       "      <td>special train ordinari research businessmen ne...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                                 .T .A  \\\n",
       "0  1.0  problem concern make descript difficulti invol...      \n",
       "1  2.0  actual pertin data oppos refer entir articl re...      \n",
       "2  3.0                 inform scienc give definit possibl      \n",
       "3  4.0  imag recognit method automat transform print t...      \n",
       "4  5.0  special train ordinari research businessmen ne...      \n",
       "\n",
       "                                                  .W .B  \n",
       "0  problem concern make descript difficulti invol...     \n",
       "1  actual pertin data oppos refer entir articl re...     \n",
       "2                 inform scienc give definit possibl     \n",
       "3  imag recognit method automat transform print t...     \n",
       "4  special train ordinari research businessmen ne...     "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "preprocessedQuery = pd.read_csv('../../cisiData/cisiQueryPreprocessed.csv', index_col=[0])\n",
    "preprocessedQuery.fillna('', inplace=True)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'.T': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'},\n",
       "  '.A': {0: ''},\n",
       "  '.W': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d = {}\n",
    "d[1] = preprocessedQuery.loc[preprocessedQuery['.I'] == 1, ['.T', '.A', '.W']].to_dict()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "obj = {\n",
    "    'bla':{\n",
    "        'reslut':{\n",
    "            1: {'.T': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'},\n",
    "                '.A': {0: ''},\n",
    "                '.W': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'}},\n",
    "\n",
    "             2: {'.T': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'},\n",
    "                 '.A': {0: ''},\n",
    "                 '.W': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'}},\n",
    "\n",
    "             3: {'.T': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'},\n",
    "                 '.A': {0: ''},\n",
    "                 '.W': {0: 'problem concern make descript difficulti involv automat retriev approxim usual relev content articl titl'}}\n",
    "        },\n",
    "        'correcting': 'query string'\n",
    "    }\n",
    "}\n",
    "\n",
    "evaluateObj = {\n",
    "    'result':{\n",
    "        'precision':0.005,\n",
    "        'recall': 0.005,\n",
    "        'MAP': 0.004,\n",
    "        'MRR': 0.008\n",
    "    },\n",
    "    'n':10\n",
    "}\n",
    "obj['bla']['reslut'][1]['.T'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1033.0, 958.0, 429.0, 90.0, 1054.0, 596.0, 550.0, 29.0, 486.0, 479.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def search(query,n:int):\n",
    "    querytfidf = transformer.transform(query)\n",
    "\n",
    "    cos = cosine_similarity(querytfidf,tfidfTable).flatten()\n",
    "    resultList = cos.argsort(axis=0)[-n:][::-1]\n",
    "    ids = []\n",
    "    for i in resultList:\n",
    "        ids.append(data.loc[i,'.I'])\n",
    "        \n",
    "    return ids\n",
    "    return query['.W'].tolist()[0]\n",
    "\n",
    "# ex query num 1 (too bad result)\n",
    "search(pd.DataFrame(preprocessedQuery.loc[preprocessedQuery.index == 0,:]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.0, 447.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'note pseudo relev'\n",
    "w = ' singl term document cover two distinct mean especi usag design secur accept doctrin attribut mathemat valid repres seriou situat mere careless ambigu'\n",
    "a = 'taube'\n",
    "test = pd.DataFrame([[t,w,a]], columns=['.T', '.W', '.A'])\n",
    "search(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryingData(qDataFrame:pd.DataFrame, n):\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for i in qDataFrame.index:\n",
    "        try:\n",
    "            resultDict:dict = {}\n",
    "            tempList:list = search(pd.DataFrame(qDataFrame.loc[qDataFrame.index == i,:]), n)\n",
    "            for id in range(1,n+1):\n",
    "                resultDict[str(id)] = tempList[id - 1]\n",
    "            result = result.append(resultDict, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1033.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1156.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5      6       7       8       9  \\\n",
       "0  1033.0   958.0   429.0    90.0  1054.0  596.0   550.0    29.0   486.0   \n",
       "1  1156.0  1158.0  1155.0  1138.0   532.0  552.0   462.0  1377.0   175.0   \n",
       "2    60.0   537.0   599.0  1027.0   554.0  572.0  1022.0   445.0   598.0   \n",
       "3   666.0  1280.0  1294.0   601.0  1105.0  643.0   565.0    72.0  1144.0   \n",
       "4   458.0   538.0  1307.0  1282.0   648.0  462.0   827.0  1054.0   826.0   \n",
       "\n",
       "      10  \n",
       "0  479.0  \n",
       "1  179.0  \n",
       "2  553.0  \n",
       "3  633.0  \n",
       "4  319.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queriesResult = queryingData(preprocessedQuery, 10)\n",
    "queriesResult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def reSizeLists(l1:list, l2:list):\n",
    "    '''resize lists to have the same len'''\n",
    "    if len(l1) < len(l2):\n",
    "        l2 = l2[0:len(l1)]\n",
    "    while len(l1) > len(l2):\n",
    "        l1 = l1[0:len(l2)]\n",
    "\n",
    "    return l1, l2\n",
    "\n",
    "\n",
    "def precWithoutOrder(l1:list,l2:list):\n",
    "    ''' calculate precision witout orering'''\n",
    "    try:\n",
    "        return len(set(l1).intersection(set(l2))) / len(l2)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calcMAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte MAP'''\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "\n",
    "    for i in resData.index:\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "\n",
    "\n",
    "        prec = precision_score(qresArray, resArray, average='micro')\n",
    "        # prec = precWithoutOrder(qresArray, resArray)\n",
    "\n",
    "        precisionsAtK.append(prec)\n",
    "\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    return precisionAtK\n",
    "\n",
    "def calcMAPrecisionAtKOrder(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte MAP'''\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "\n",
    "    for i in resData.index:\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "\n",
    "\n",
    "        # prec = precision_score(qresArray, resArray, average='micro')\n",
    "        prec = precWithoutOrder(qresArray, resArray)\n",
    "\n",
    "        precisionsAtK.append(prec)\n",
    "\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    return precisionAtK\n",
    "\n",
    "def calcAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte Average Precision'''\n",
    "    precisionsAtK:list = []\n",
    "\n",
    "    for i in resData.index:\n",
    "        precisionOnQuery = []\n",
    "\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "        for lenI in range(0,len(qresArray)):\n",
    "\n",
    "            tempRes:list = resArray[0:lenI+1].tolist()\n",
    "            tempQRes:list = qresArray[0:lenI+1].tolist()\n",
    "            precisionOnQuery.append(precision_score(tempQRes, tempRes, average='micro'))\n",
    "\n",
    "        try:\n",
    "            precisionsAtK.append(sum(precisionOnQuery) / len(precisionOnQuery))\n",
    "        except ZeroDivisionError: \n",
    "            precisionsAtK.append(0)\n",
    "    return precisionsAtK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .I  data\n",
       "0   1    28\n",
       "1   1    35\n",
       "2   1    38\n",
       "3   1    42\n",
       "4   1    43"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qrelsFrame = pd.read_csv('../../cisiData/cisiQRels.csv', index_col=[0])\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005263157894736842\n",
      "0.05749269005847955\n"
     ]
    }
   ],
   "source": [
    "# K = 10\n",
    "print(calcMAPrecisionAtK(queriesResult, qrelsFrame))\n",
    "print(calcMAPrecisionAtKOrder(queriesResult, qrelsFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.023830409356725146 l1 - qFreq - DFreq - just .W ngram = (1,2)\n",
    "0.08249269005847952 .W l2 ngram = (1,2) .T l2 ngram = (1,2) fill - .A l1 - Freq - not order - q1 q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10\n",
    "averagePrecision = calcAPrecisionAtK(queriesResult, qrelsFrame)\n",
    "for i in range(0,len(averagePrecision), 2):\n",
    "    print(i+1, end=' - '); print(averagePrecision[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "resultDataFrame = pd.DataFrame(columns=['.I','data', 'rank'])\n",
    "\n",
    "\n",
    "for row in queriesResult.index:\n",
    "    temp = queriesResult.loc[row].to_list()\n",
    "    ke = []\n",
    "    rank = []\n",
    "    for i in range(0,len(temp)):\n",
    "        ke.append(row + 1)\n",
    "        rank.append(i+1)\n",
    "    lot = zip(ke,temp, rank)\n",
    "    tempdata = pd.DataFrame(lot, columns=['.I','data', 'rank'])\n",
    "\n",
    "    resultDataFrame = resultDataFrame.append(tempdata, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>112</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>112</td>\n",
       "      <td>495.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>112</td>\n",
       "      <td>898.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       .I    data rank\n",
       "1117  112  1144.0    8\n",
       "1118  112   495.0    9\n",
       "1119  112   898.0   10"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDataFrame[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .I  data\n",
       "0   1    28\n",
       "1   1    35\n",
       "2   1    38\n",
       "3   1    42\n",
       "4   1    43"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanReciprocalRank(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "\n",
    "\n",
    "    MAX_RANK = 100000\n",
    "\n",
    "    hits = pd.merge(qrelsData, resData,\n",
    "        on=[\".I\", \"data\"],\n",
    "        how=\"left\").fillna(MAX_RANK)\n",
    "\n",
    "    mrr = (1 / hits.groupby('.I')['rank'].min()).mean()\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42221963241436916"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcMeanReciprocalRank(resultDataFrame, qrelsFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i stoped here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ad1a5a807b944b1335f606d031e49130ad1da3a9de40b9fa5d942006ec880ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IRProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
