{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CISIDATA = '../../../../CISI/CISI.ALL'\n",
    "import re\n",
    "IDMarker = re.compile('(\\.I.)')\n",
    "allMarkers = re.compile('(\\.[ITABWX] )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queries info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CISIQUERY = '../../../../CISI/CISI.QRY'\n",
    "CISIQRELS = '../../../../CISI/CISI.REL'\n",
    "import re\n",
    "queryMarkers = re.compile('(\\.[ITAWB] )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(PATH, marker):\n",
    "    \"\"\"get the data from the file and split it by ID\"\"\"\n",
    "    with open(PATH, 'r') as f:\n",
    "        t = f.read().replace('\\n', ' ')\n",
    "        lines = re.split(marker, t)\n",
    "        lines.pop(0)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte CISI.ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisiData = getData(CISIDATA, allMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFrame = pd.DataFrame(columns=['.I','.T','.A','.B','.W','.X'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.A': None,\n",
    "    '.B': None,\n",
    "    '.W': None,\n",
    "    '.X': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cisiData), 2):\n",
    "    if (notTheFirst and cisiData[i].strip() == '.I'):\n",
    "        dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cisiData[i].strip()] = cisiData[i+1].strip()\n",
    "    notTheFirst = True\n",
    "dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.to_csv('../../cisiData/cisiCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte query.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisiQuery = getData(CISIQUERY, queryMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qDataFrame = pd.DataFrame(columns=['.I','.T','.A','.W','.B'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.A': None,\n",
    "    '.W': None,\n",
    "    '.B': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cisiQuery), 2):\n",
    "    if (notTheFirst and cisiQuery[i].strip() == '.I'):\n",
    "        qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cisiQuery[i].strip()] = cisiQuery[i+1].strip()\n",
    "    notTheFirst = True\n",
    "qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "qDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qDataFrame.to_csv('../../cisiData/cisiQueryCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte qrels.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getRles(path):\n",
    "    with open(path, 'r') as f:\n",
    "        global qrlesList\n",
    "        qrlesList = f.read().split('\\n')\n",
    "        return qrlesList\n",
    "\n",
    "qrelsData = getRles(CISIQRELS)\n",
    "qrelsFrame = pd.DataFrame(columns=['.I', 'data'])\n",
    "seriesDict:dict = {'.I':None, 'data':None}\n",
    "seriesData = seriesDict.copy()\n",
    "for i in qrelsData:\n",
    "    try:\n",
    "        element = i.split()\n",
    "        seriesData['.I'] = int(element[0])\n",
    "        seriesData['data'] = int(element[1])\n",
    "        qrelsFrame = qrelsFrame.append(seriesData, ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelsFrame.to_csv('../../cisiData/cisiQRels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df:pd.DataFrame = pd.read_csv('../../cisiData/cisiCsv.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:,'.T'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.W'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.A'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../cisiData/cisiDataCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numbers to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import re\n",
    "reg = r'([0-9]+)'\n",
    "\n",
    "def isFLoat(strNum):\n",
    "    try:\n",
    "        float(strNum)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def converteNumbers(text):\n",
    "    tempText = text.split()\n",
    "    newText = []\n",
    "    for word in tempText:\n",
    "        tempList = re.split(reg,word)\n",
    "        for miniWord in tempList:\n",
    "            if miniWord.isdigit() or isFLoat(miniWord):\n",
    "                temp = p.number_to_words(miniWord)\n",
    "                newText.append(removePunctuation(temp))\n",
    "            else:\n",
    "                newText.append(miniWord)        \n",
    "    tempText = ' '.join(newText)\n",
    "    return tempText\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "def removePunctuation(text):\n",
    "    global translator\n",
    "    return text.translate(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWhiteSpace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def removeStopWords(text):\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    wt = word_tokenize(text)\n",
    "    filteredText = [word for word in wt if word not in sw]\n",
    "    return ' '.join(filteredText)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemWords(text):\n",
    "    global stemmer\n",
    "    wt = word_tokenize(text)\n",
    "    stems = []\n",
    "    for word in wt:\n",
    "        temp = stemmer.stem(word)\n",
    "        # if not temp == word:\n",
    "        #     temp = correctWords(temp)\n",
    "        stems.append(temp)\n",
    "    return ' '.join(stems)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag, defaultdict\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lemmatizeWords(text):\n",
    "    # wt = word_tokenize(text)\n",
    "    # lemmas = [lemmatizer.lemmatize(word, pos='a') for word in wt]\n",
    "    # return ' '.join(lemmas)\n",
    "    # return text\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemmas = [lmtzr.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens) ]\n",
    "    return ' '.join(lemmas)\n",
    "# lemmatizeWords('hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "correct_words = words.words()\n",
    "incorrectWords = '''preliminari'''.split()\n",
    "result = []\n",
    "def correctWords(text):\n",
    "    for word in text:\n",
    "        try:\n",
    "            temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                                      set(ngrams(w, 2))),w)\n",
    "                                      for w in correct_words if w[0] == word[0]]\n",
    "            result.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        except:\n",
    "            pass\n",
    "    return ' '.join(result)\n",
    "# correctWords(incorrectWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cisi process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def TitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def abstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "# i didn't do it yet on cisi (converte date to timestamp)\n",
    "def publicationPreProcesse(p): \n",
    "    # tempText = p.replace('cisi ','')\n",
    "    # return pd.to_datetime(tempText)\n",
    "    return p\n",
    "    \n",
    "def authorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word.replace(',','')))\n",
    "    names = ' '.join(l)\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocessedData(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            tempT = tempA = tempB = tempW = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = TitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = authorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = abstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "\n",
    "            seriesData['.I'] = i+1\n",
    "            seriesData['.T'] = tempT\n",
    "            seriesData['.A'] = tempA\n",
    "            seriesData['.B'] = tempB\n",
    "            seriesData['.W'] = tempW\n",
    "            \n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cisiData/cisiDataCleaned.csv', index_col=[0])\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta = preprocessedData(data)\n",
    "processedDAta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta.to_csv('../../cisiData/cisiDataPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def qTitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def qAbstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def qAuthorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word.replace(',','')))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "\n",
    "# i didn't do it yet on cisi (converte date to timestamp)\n",
    "def qPublicationPreProcesse(p):\n",
    "    # tempText = p.replace('cisi ','')\n",
    "    # return pd.to_datetime(tempText)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocesseQuery(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame() \n",
    "    seriesDict:dict = {} \n",
    "    seriesData = seriesDict.copy()\n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            templist = []\n",
    "            tempT = tempA = tempW = tempB = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = qTitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = qAuthorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = qAbstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = qPublicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "\n",
    "\n",
    "            seriesData['.I'] = i+1\n",
    "            seriesData['.T'] = tempT\n",
    "            seriesData['.A'] = tempA\n",
    "            seriesData['.W'] = tempW\n",
    "            seriesData['.B'] = tempB\n",
    "            pdataFrame = pdataFrame.append(seriesData, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "querydf = pd.read_csv('../../cisiData/cisiQueryCsv.csv', index_col=[0])\n",
    "querydf.fillna('', inplace=True)\n",
    "querydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery = preprocesseQuery(querydf)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.to_csv('../../cisiData/cisiQueryPreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.B</th>\n",
       "      <th>.W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>eighteen edit dewey decim classif</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>present studi histori dewey decim classif firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>use make technic librari</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>report analysi six thousand three hundr act us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>two kind power essay bibliograph control</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>relationship organ control write organ control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>system analysi univ librari final report resea...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>establish nine new univ one thousand nine hund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>librari manag game report research project</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>although use game profess educ becom widesprea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                                 .T .A .B  \\\n",
       "0  1.0                  eighteen edit dewey decim classif         \n",
       "1  2.0                           use make technic librari         \n",
       "2  3.0           two kind power essay bibliograph control         \n",
       "3  4.0  system analysi univ librari final report resea...         \n",
       "4  5.0         librari manag game report research project         \n",
       "\n",
       "                                                  .W  \n",
       "0  present studi histori dewey decim classif firs...  \n",
       "1  report analysi six thousand three hundr act us...  \n",
       "2  relationship organ control write organ control...  \n",
       "3  establish nine new univ one thousand nine hund...  \n",
       "4  although use game profess educ becom widesprea...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cisiData/cisiDataPreprocessed.csv', index_col=[0])\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# this is old cell for build index model with merge coulmns into one coulmn (not work now)\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import  cosine_similarity, linear_kernel\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfTable = tfidf.fit_transform(data['.W'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1460x6820 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 83388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "\n",
    "\n",
    "transformer = FeatureUnion([\n",
    "                ('title_tfidf', \n",
    "                  Pipeline([('extract_field',\n",
    "                              FunctionTransformer(lambda x: x['.T'], \n",
    "                                                  validate=False)),\n",
    "                            ('tfidf', \n",
    "                              TfidfVectorizer())])),\n",
    "                # ('author_tfidf', \n",
    "                #   Pipeline([('extract_field', \n",
    "                #               FunctionTransformer(lambda x: x['.A'], \n",
    "                #                                   validate=False)),\n",
    "                #             ('tfidf', \n",
    "                #               TfidfVectorizer())])),\n",
    "                ('abstract_tfidf',\n",
    "                 Pipeline([('extract_field',\n",
    "                            FunctionTransformer(lambda x: x['.W'],\n",
    "                                                  validate=False)),\n",
    "                            ('tfidf',\n",
    "                              TfidfVectorizer())]))])\n",
    "tfidfTable = transformer.fit_transform(data)\n",
    "tfidfTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5978547 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51193249, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfTable.toarray()[1000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>problem concern make descript titl difficulti ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>actual pertin data oppos refer entir articl re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inform scienc give definit possibl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>imag recognit method automat transform print t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>special train ordinari research businessmen ne...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I .T .A                                                 .W .B\n",
       "0  1.0        problem concern make descript titl difficulti ...   \n",
       "1  2.0        actual pertin data oppos refer entir articl re...   \n",
       "2  3.0                       inform scienc give definit possibl   \n",
       "3  4.0        imag recognit method automat transform print t...   \n",
       "4  5.0        special train ordinari research businessmen ne...   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "preprocessedQuery = pd.read_csv('../../cisiData/cisiQueryPreprocessed.csv', index_col=[0])\n",
    "preprocessedQuery.fillna('', inplace=True)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[722.0, 429.0, 589.0, 603.0, 1299.0, 1281.0, 38.0, 813.0, 620.0, 836.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query,n:int):\n",
    "    querytfidf = transformer.transform(query)\n",
    "\n",
    "    cos = cosine_similarity(querytfidf,tfidfTable).flatten()\n",
    "\n",
    "    resultList = cos.argsort(axis=0)[-n:][::-1]\n",
    "    ids = []\n",
    "    for i in resultList:\n",
    "        ids.append(data.loc[i,'.I'])\n",
    "        \n",
    "    return ids\n",
    "\n",
    "# ex query num 1 (too bad result)\n",
    "search(pd.DataFrame(preprocessedQuery.loc[preprocessedQuery.index == 0,:]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryingData(qDataFrame:pd.DataFrame, n):\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for i in qDataFrame.index:\n",
    "        try:\n",
    "            resultDict:dict = {}\n",
    "            tempList:list = search(pd.DataFrame(qDataFrame.loc[qDataFrame.index == i,:]), n)\n",
    "            for id in range(1,n+1):\n",
    "                resultDict[str(id)] = tempList[id - 1]\n",
    "            result = result.append(resultDict, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>.T</th>\n",
       "      <th>.A</th>\n",
       "      <th>.W</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>problem concern make descript titl difficulti ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>actual pertin data oppos refer entir articl re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inform scienc give definit possibl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>imag recognit method automat transform print t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>special train ordinari research businessmen ne...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I .T .A                                                 .W .B\n",
       "0  1.0        problem concern make descript titl difficulti ...   \n",
       "1  2.0        actual pertin data oppos refer entir articl re...   \n",
       "2  3.0                       inform scienc give definit possibl   \n",
       "3  4.0        imag recognit method automat transform print t...   \n",
       "4  5.0        special train ordinari research businessmen ne...   "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queriesPath = '../../cisiData/cisiQueryPreprocessed.csv'\n",
    "queriesData = pd.read_csv(queriesPath, index_col=[0])\n",
    "queriesData.fillna('', inplace=True)\n",
    "queriesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>722.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1138.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1038.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>1106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7      8       9  \\\n",
       "0   722.0   429.0   589.0   603.0  1299.0  1281.0    38.0  813.0   620.0   \n",
       "1  1138.0  1155.0   565.0   532.0  1096.0   790.0  1136.0   58.0   309.0   \n",
       "2   469.0  1179.0  1181.0  1133.0   445.0    85.0   599.0  540.0  1077.0   \n",
       "3   179.0   790.0   175.0    77.0  1224.0   565.0  1120.0   72.0   315.0   \n",
       "4  1038.0  1105.0   710.0  1166.0   122.0  1361.0   862.0  459.0  1136.0   \n",
       "\n",
       "       10  \n",
       "0   836.0  \n",
       "1   562.0  \n",
       "2   803.0  \n",
       "3  1294.0  \n",
       "4  1106.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queriesResult = queryingData(queriesData, 10)\n",
    "queriesResult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def reSizeLists(l1:list, l2:list):\n",
    "    '''resize lists to have the same len'''\n",
    "    if len(l1) < len(l2):\n",
    "        l2 = l2[0:len(l1)]\n",
    "    while len(l1) > len(l2):\n",
    "        l1 = l1[0:len(l2)]\n",
    "\n",
    "    return l1, l2\n",
    "\n",
    "\n",
    "def precWithoutOrder(l1:list,l2:list):\n",
    "    ''' calculate precision witout orering'''\n",
    "    try:\n",
    "        return len(set(l1).intersection(set(l2))) / len(l2)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calcMAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte MAP'''\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "\n",
    "    for i in resData.index:\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "\n",
    "\n",
    "        prec = precision_score(qresArray, resArray, average='micro')\n",
    "        precisionsAtK.append(prec)\n",
    "        if not prec == 0:\n",
    "            print(prec)\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    return precisionAtK\n",
    "\n",
    "def calcAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte Average Precision'''\n",
    "    precisionsAtK:list = []\n",
    "\n",
    "    for i in resData.index:\n",
    "        precisionOnQuery = []\n",
    "\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "        for lenI in range(0,len(qresArray)):\n",
    "\n",
    "            tempRes:list = resArray[0:lenI+1].tolist()\n",
    "            tempQRes:list = qresArray[0:lenI+1].tolist()\n",
    "            precisionOnQuery.append(precision_score(tempQRes, tempRes, average='micro'))\n",
    "\n",
    "        try:\n",
    "            precisionsAtK.append(sum(precisionOnQuery) / len(precisionOnQuery))\n",
    "        except ZeroDivisionError: \n",
    "            precisionsAtK.append(0)\n",
    "    return precisionsAtK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .I  data\n",
       "0   1    28\n",
       "1   1    35\n",
       "2   1    38\n",
       "3   1    42\n",
       "4   1    43"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qrelsFrame = pd.read_csv('../../cisiData/cisiQRels.csv', index_col=[0])\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1111111111111111\n",
      "0.16666666666666666\n",
      "1.1777777777777778\n",
      "76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015497076023391813"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K = 10\n",
    "calcMAPrecisionAtK(queriesResult, qrelsFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10\n",
    "averagePrecision = calcAPrecisionAtK(queriesResult, qrelsFrame)\n",
    "for i in range(0,len(averagePrecision), 2):\n",
    "    print(i+1, end=' - '); print(averagePrecision[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i stoped here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ad1a5a807b944b1335f606d031e49130ad1da3a9de40b9fa5d942006ec880ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IRProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
