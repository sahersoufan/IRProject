{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CISIDATA = '../../../../CISI/CISI.ALL'\n",
    "import re\n",
    "IDMarker = re.compile('(\\.I.)')\n",
    "allMarkers = re.compile('(\\.[ITABWX] )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queries info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CISIQUERY = '../../../../CISI/CISI.QRY'\n",
    "CISIQRELS = '../../../../CISI/CISI.REL'\n",
    "import re\n",
    "queryMarkers = re.compile('(\\.[ITAWB] )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(PATH, marker):\n",
    "    \"\"\"get the data from the file and split it by ID\"\"\"\n",
    "    with open(PATH, 'r') as f:\n",
    "        t = f.read().replace('\\n', ' ')\n",
    "        lines = re.split(marker, t)\n",
    "        lines.pop(0)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte CISI.ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisiData = getData(CISIDATA, allMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFrame = pd.DataFrame(columns=['.I','.T','.A','.B','.W','.X'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.A': None,\n",
    "    '.B': None,\n",
    "    '.W': None,\n",
    "    '.X': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cisiData), 2):\n",
    "    if (notTheFirst and cisiData[i].strip() == '.I'):\n",
    "        dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cisiData[i].strip()] = cisiData[i+1].strip()\n",
    "    notTheFirst = True\n",
    "dataFrame = dataFrame.append(seriesData, ignore_index=True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.to_csv('../../cisiData/cisiCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte query.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisiQuery = getData(CISIQUERY, queryMarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qDataFrame = pd.DataFrame(columns=['.I','.T','.A','.W','.B'])\n",
    "seriesDict:dict = {\n",
    "    '.I': None,\n",
    "    '.T': None,\n",
    "    '.A': None,\n",
    "    '.W': None,\n",
    "    '.B': None\n",
    "}\n",
    "seriesData = seriesDict.copy()\n",
    "notTheFirst = False\n",
    "for i in range(0, len(cisiQuery), 2):\n",
    "    if (notTheFirst and cisiQuery[i].strip() == '.I'):\n",
    "        qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "        seriesData = seriesDict.copy()\n",
    "    \n",
    "    seriesData[cisiQuery[i].strip()] = cisiQuery[i+1].strip()\n",
    "    notTheFirst = True\n",
    "qDataFrame = qDataFrame.append(seriesData, ignore_index=True)\n",
    "qDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qDataFrame.to_csv('../../cisiData/cisiQueryCsv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converte qrels.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getRles(path):\n",
    "    with open(path, 'r') as f:\n",
    "        global qrlesList\n",
    "        qrlesList = f.read().split('\\n')\n",
    "        return qrlesList\n",
    "\n",
    "qrelsData = getRles(CISIQRELS)\n",
    "qrelsFrame = pd.DataFrame(columns=['.I', 'data'])\n",
    "seriesDict:dict = {'.I':None, 'data':None}\n",
    "seriesData = seriesDict.copy()\n",
    "for i in qrelsData:\n",
    "    try:\n",
    "        element = i.split()\n",
    "        seriesData['.I'] = int(element[0])\n",
    "        seriesData['data'] = int(element[1])\n",
    "        qrelsFrame = qrelsFrame.append(seriesData, ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrelsFrame.to_csv('../../cisiData/cisiQRels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df:pd.DataFrame = pd.read_csv('../../cisiData/cisiCsv.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:,'.T'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.W'].isnull().value_counts(), end='\\n\\n')\n",
    "print(df.loc[:,'.A'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../cisiData/cisiDataCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numbers to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import re\n",
    "reg = r'([0-9]+)'\n",
    "\n",
    "def isFLoat(strNum):\n",
    "    try:\n",
    "        float(strNum)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def converteNumbers(text):\n",
    "    tempText = text.split()\n",
    "    newText = []\n",
    "    for word in tempText:\n",
    "        tempList = re.split(reg,word)\n",
    "        for miniWord in tempList:\n",
    "            if miniWord.isdigit() or isFLoat(miniWord):\n",
    "                temp = p.number_to_words(miniWord)\n",
    "                newText.append(removePunctuation(temp))\n",
    "            else:\n",
    "                newText.append(miniWord)        \n",
    "    tempText = ' '.join(newText)\n",
    "    return tempText\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "def removePunctuation(text):\n",
    "    global translator\n",
    "    return text.translate(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWhiteSpace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "\n",
    "def removeStopWords(text):\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    wt = word_tokenize(text)\n",
    "    filteredText = [word for word in wt if word not in sw]\n",
    "    return ' '.join(filteredText)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calcFreq(tokens):\n",
    "    listOfTokens = tokens.split()\n",
    "    fdist = FreqDist(word for word in listOfTokens)\n",
    "    fdistKeys = np.array(list(fdist.keys()))\n",
    "    freqOfWords = [fdist.freq(x) for x in fdistKeys]\n",
    "\n",
    "    q1, q3 = np.percentile(freqOfWords, [25, 75])\n",
    "    # q3 = np.percentile(freqOfWords, 75, interpolation='midpoint')\n",
    "    IQR = q3 - q1\n",
    "    AVG = np.mean(freqOfWords)\n",
    "    AvgRelValue = round(AVG * len(listOfTokens))\n",
    "    Q1RelValue = round(q1* len(listOfTokens))\n",
    "    Q3RelValue = round(q3 * len(listOfTokens))\n",
    "    st = ' '.join(listOfTokens)\n",
    "\n",
    "    for i in range(0,len(freqOfWords)):\n",
    "        if freqOfWords[i] < q1 - 1.5*IQR:\n",
    "            wordRelValue = round(freqOfWords[i] * len(listOfTokens))\n",
    "            sub = Q1RelValue - wordRelValue\n",
    "            word = fdistKeys[i]\n",
    "            stForAppend = word * sub\n",
    "            st = st + stForAppend\n",
    "\n",
    "        if freqOfWords[i] > q3 + 1.5*IQR:\n",
    "            wordRelValue = round(freqOfWords[i] * len(listOfTokens))\n",
    "            sub = wordRelValue - Q3RelValue\n",
    "            word = fdistKeys[i]\n",
    "            st = st.replace(word, '', sub)\n",
    "    \n",
    "    return removeWhiteSpace(st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = '''note pseudo mathemat relev taube recent number articl book report deal inform system e document retriev system advanc doctrin system evalu term degre percentag relev provid although seem littl agreement relev mean doubt quantifi nevertheless grow agreement fix formal relationship exist relev recal perform system thu find literatur frankli subject notion relev report individu user equat curv mathemat formul presum provid numer measur recal relev characterist inform system phenomenon shift back forth admittedli subject non mathemat term equat term give mathemat valu mathemat definit ancient parallel discus probabl one cours legisl mean term depend alic point master user term hand use singl term document cover two distinct mean especi usag design secur accept doctrin attribut mathemat valid repres seriou situat mere careless ambigu'''\n",
    "qt = '''problem concern make descript titl difficulti involv automat retriev articl approxim titl usual relev content articl titl'''\n",
    "calcFreq(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def checkOutLiers(lineOfPercent):\n",
    "#     try:\n",
    "#         q1 = np.percentile(lineOfPercent, 25, interpolation='midpoint')\n",
    "#         q3 = np.percentile(lineOfPercent, 75, interpolation='midpoint')\n",
    "#         IQR = q3 - q1\n",
    "#         AVG = np.mean(lineOfPercent)\n",
    "#         lineAfterRemoveOutLiers = []\n",
    "#         for i in lineOfPercent:\n",
    "#             if i < q1 - 1.5*IQR:\n",
    "#                 lineAfterRemoveOutLiers.append(AVG)\n",
    "#             elif i > q3 + 1.5*IQR:\n",
    "#               lineAfterRemoveOutLiers.append(AVG)\n",
    "#             else:\n",
    "#              lineAfterRemoveOutLiers.append(i)\n",
    "\n",
    "#         return lineAfterRemoveOutLiers\n",
    "#     except:\n",
    "#         return lineOfPercent\n",
    "\n",
    "\n",
    "\n",
    "# def checkCoverage(queryTokens) -> list:\n",
    "#     covDoc = []\n",
    "\n",
    "#     qTokens = np.array(queryTokens)\n",
    "#     for doc in wordsFreq:\n",
    "#         WordsList = np.array(list(doc.keys()))\n",
    "#         common = np.intersect1d(qTokens, WordsList)\n",
    "#         freqOfWords = [doc.freq(x) for x in common]\n",
    "#         common = checkOutLiers(freqOfWords)\n",
    "#         try:\n",
    "#             covDoc.append(sum(common))\n",
    "#         except:\n",
    "#             covDoc.append(0)\n",
    "    \n",
    "#     sortedList = np.array(covDoc).argsort(axis=0)[::-1]\n",
    "#     return sortedList\n",
    "\n",
    "# # checkCoverage(queryTokens=['saher', 'fatima', 'man', 'hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemWords(text):\n",
    "    global stemmer\n",
    "    wt = word_tokenize(text)\n",
    "    stems = []\n",
    "    for word in wt:\n",
    "        temp = stemmer.stem(word)\n",
    "        # if not temp == word:\n",
    "        #     temp = correctWords(temp)\n",
    "        stems.append(temp)\n",
    "    return ' '.join(stems)\n",
    "    # return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag, defaultdict\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lemmatizeWords(text):\n",
    "    # wt = word_tokenize(text)\n",
    "    # lemmas = [lemmatizer.lemmatize(word, pos='a') for word in wt]\n",
    "    # return ' '.join(lemmas)\n",
    "    # return text\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemmas = [lmtzr.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens) ]\n",
    "    return ' '.join(lemmas)\n",
    "# lemmatizeWords('hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "correct_words = words.words()\n",
    "incorrectWords = '''preliminari'''.split()\n",
    "result = []\n",
    "def correctWords(text):\n",
    "    for word in text:\n",
    "        try:\n",
    "            temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                                      set(ngrams(w, 2))),w)\n",
    "                                      for w in correct_words if w[0] == word[0]]\n",
    "            result.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        except:\n",
    "            pass\n",
    "    return ' '.join(result)\n",
    "# correctWords(incorrectWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cisi process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def TitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "def abstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "# i didn't do it yet on cisi (converte date to timestamp)\n",
    "def publicationPreProcesse(p): \n",
    "    # tempText = p.replace('cisi ','')\n",
    "    # return pd.to_datetime(tempText)\n",
    "    return p\n",
    "    \n",
    "def authorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word))\n",
    "    names = ' '.join(l)\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocessedData(dataFrame:pd.DataFrame):\n",
    "    pdataFrame = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            tempT = tempA = tempW = ''\n",
    "            tempB = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = TitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = authorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = abstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "\n",
    "            seriesDict['.I'] = i+1\n",
    "            seriesDict['data'] = calcFreq(' '.join([tempT, tempA, tempW]))\n",
    "            seriesDict['.B'] = tempB\n",
    "            \n",
    "            pdataFrame = pdataFrame.append(seriesDict, ignore_index=True)\n",
    "            seriesDict = {}\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    pdataFrame.fillna('', inplace=True)\n",
    "    return pdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cisiData/cisiDataCleaned.csv', index_col=[0])\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta = preprocessedData(data)\n",
    "processedDAta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDAta.to_csv('../../cisiData/cisiDataPreprocessedV2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def qTitlePreProcesse(t):\n",
    "    tempText = toLower(t)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "\n",
    "    return tempText\n",
    "\n",
    "def qAbstractPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    tempText = removePunctuation(tempText)\n",
    "    tempText = converteNumbers(tempText)\n",
    "    tempText = removeWhiteSpace(tempText)\n",
    "    tempText = removeStopWords(tempText)\n",
    "    tempText = stemWords(tempText)\n",
    "    tempText = lemmatizeWords(tempText)\n",
    "    return tempText\n",
    "\n",
    "def qAuthorPreProcesse(a):\n",
    "    tempText = toLower(a)\n",
    "    lis = tempText.split(' ')\n",
    "    names = ' '\n",
    "    l = []\n",
    "    for word in lis:\n",
    "      if ',' in word:\n",
    "          l.append(removePunctuation(word))\n",
    "    names = ' '.join(l)\n",
    "    return names\n",
    "\n",
    "\n",
    "# i didn't do it yet on cisi (converte date to timestamp)\n",
    "def qPublicationPreProcesse(p):\n",
    "    # tempText = p.replace('cisi ','')\n",
    "    # return pd.to_datetime(tempText)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocesseQuery(dataFrame:pd.DataFrame):\n",
    "    qdataFrame = pd.DataFrame()\n",
    "    seriesDict:dict = {} \n",
    "    for i in dataFrame.index:\n",
    "        try:\n",
    "            tempT = tempA = tempW = ''\n",
    "            tempB = None\n",
    "            if not dataFrame.loc[i, '.T'] == '':\n",
    "                tempT = TitlePreProcesse(dataFrame.loc[i, '.T'])\n",
    "            if not dataFrame.loc[i, '.A'] == '':\n",
    "                tempA = authorPreProcesse(dataFrame.loc[i, '.A'])\n",
    "            if not dataFrame.loc[i, '.B'] == '':\n",
    "                tempB = publicationPreProcesse(dataFrame.loc[i, '.B'])\n",
    "            if not dataFrame.loc[i, '.W'] == '':\n",
    "                tempW = abstractPreProcesse(dataFrame.loc[i, '.W'])\n",
    "\n",
    "            seriesDict['.I'] = i+1\n",
    "            seriesDict['data'] = calcFreq(' '.join([tempT, tempA, tempW]))\n",
    "            seriesDict['.B'] = tempB\n",
    "            \n",
    "            qdataFrame = qdataFrame.append(seriesDict, ignore_index=True)\n",
    "            seriesDict = {}\n",
    "        except:\n",
    "            print(i)\n",
    "            raise \n",
    "    qdataFrame.fillna('', inplace=True)\n",
    "    return qdataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "querydf = pd.read_csv('../../cisiData/cisiQueryCsv.csv', index_col=[0])\n",
    "querydf.fillna('', inplace=True)\n",
    "querydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery = preprocesseQuery(querydf)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedQuery.to_csv('../../cisiData/cisiQueryPreprocessedV2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>eighteen comaromi present studi decim classif ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>make slater report analysi six thousand three ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>two kind essay wilson relationship organ organ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>system analysi final project buckland new one ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>librari report research project brophy althoug...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                               data .B\n",
       "0  1.0  eighteen comaromi present studi decim classif ...   \n",
       "1  2.0  make slater report analysi six thousand three ...   \n",
       "2  3.0  two kind essay wilson relationship organ organ...   \n",
       "3  4.0  system analysi final project buckland new one ...   \n",
       "4  5.0  librari report research project brophy althoug...   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../cisiData/cisiDataPreprocessedV2.csv', index_col=[0])\n",
    "data.fillna('', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# this is old cell for build index model with merge coulmns into one coulmn (not work now)\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import  cosine_similarity, linear_kernel\n",
    "\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# tfidfTable = tfidf.fit_transform(data['.W'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1460x76146 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 165781 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# transformer = FeatureUnion([\n",
    "#                 # ('title_tfidf', \n",
    "#                 #   Pipeline([\n",
    "#                 #     ('extract_field',\n",
    "#                 #               FunctionTransformer(lambda x: x['.T'], \n",
    "#                 #                                   validate=False)),\n",
    "#                 #             ('tfidf', \n",
    "#                 #               TfidfVectorizer(norm='l1'))])),\n",
    "#                 # ('author_tfidf', \n",
    "#                 #   Pipeline([('extract_field', \n",
    "#                 #               FunctionTransformer(lambda x: x['.A'], \n",
    "#                 #                                   validate=False)),\n",
    "#                 #             ('tfidf', \n",
    "#                 #               TfidfVectorizer(norm='l1'))])),\n",
    "#                 ('abstract_tfidf',\n",
    "#                  Pipeline([('extract_field',\n",
    "#                             FunctionTransformer(lambda x: x['.W'],\n",
    "#                                                   validate=False)),\n",
    "#                             ('tfidf',\n",
    "#                               TfidfVectorizer(norm='l2', ngram_range=(1,4)))]))])\n",
    "# tfidfTable = transformer.fit_transform(data)\n",
    "# tfidfTable\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm='l1', ngram_range=(1,2))\n",
    "tfidfTable = vectorizer.fit_transform(data.data)\n",
    "tfidfTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02350596, 0.01374093, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0141537 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfTable.toarray()[1000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>problem concern make descript difficulti invol...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>actual pertin data oppos refer entir articl re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>inform scienc give definit possibl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>imag recognit method automat transform print t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>special train ordinari research businessmen ne...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                               data .B\n",
       "0  1.0  problem concern make descript difficulti invol...   \n",
       "1  2.0  actual pertin data oppos refer entir articl re...   \n",
       "2  3.0                 inform scienc give definit possibl   \n",
       "3  4.0  imag recognit method automat transform print t...   \n",
       "4  5.0  special train ordinari research businessmen ne...   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "preprocessedQuery = pd.read_csv('../../cisiData/cisiQueryPreprocessedV2.csv', index_col=[0])\n",
    "preprocessedQuery.fillna('', inplace=True)\n",
    "preprocessedQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[882.0, 489.0, 785.0, 531.0, 666.0, 621.0, 175.0, 429.0, 323.0, 483.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def search(query,n:int):\n",
    "    querytfidf = vectorizer.transform(query)\n",
    "\n",
    "    cos = cosine_similarity(querytfidf,tfidfTable).flatten()\n",
    "    # mostCovered = checkCoverage(query['.W'].tolist()[0].split()) \n",
    "    # # print(mostCovered[)\n",
    "    # tempResult = []\n",
    "    # for i in range(0,10):\n",
    "    #     cos[mostCovered[i]] = cos[mostCovered[i]] + 1 \n",
    "    # # print(tempResult)\n",
    "    # tempResNp = np.array(tempResult)\n",
    "    resultList = cos.argsort(axis=0)[-n:][::-1]\n",
    "    ids = []\n",
    "    for i in resultList:\n",
    "        ids.append(data.loc[i,'.I'])\n",
    "        \n",
    "    return ids\n",
    "    return query['.W'].tolist()[0]\n",
    "\n",
    "# ex query num 1 (too bad result)\n",
    "search(preprocessedQuery.loc[preprocessedQuery.index == 0,'data'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryingData(qDataFrame:pd.DataFrame, n):\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for i in qDataFrame.index:\n",
    "        try:\n",
    "            resultDict:dict = {}\n",
    "            tempList:list = search(qDataFrame.loc[qDataFrame.index == i,'data'], n)\n",
    "            for id in range(1,n+1):\n",
    "                resultDict[str(id)] = tempList[id - 1]\n",
    "            result = result.append(resultDict, ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            raise\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "      <th>.B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>problem concern make descript difficulti invol...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>actual pertin data oppos refer entir articl re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>inform scienc give definit possibl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>imag recognit method automat transform print t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>special train ordinari research businessmen ne...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .I                                               data .B\n",
       "0  1.0  problem concern make descript difficulti invol...   \n",
       "1  2.0  actual pertin data oppos refer entir articl re...   \n",
       "2  3.0                 inform scienc give definit possibl   \n",
       "3  4.0  imag recognit method automat transform print t...   \n",
       "4  5.0  special train ordinari research businessmen ne...   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queriesPath = '../../cisiData/cisiQueryPreprocessedV2.csv'\n",
    "queriesData = pd.read_csv(queriesPath, index_col=[0])\n",
    "queriesData.fillna('', inplace=True)\n",
    "queriesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>882.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1138.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>1096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>1181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>565.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>483.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7       8       9  \\\n",
       "0   882.0   489.0   785.0   531.0   666.0   621.0   175.0   429.0   323.0   \n",
       "1  1138.0  1327.0   483.0   451.0   175.0  1071.0  1236.0   565.0   797.0   \n",
       "2   469.0  1118.0    60.0   803.0   652.0   553.0  1133.0  1179.0  1161.0   \n",
       "3   565.0   175.0   890.0  1396.0   663.0   601.0   483.0   480.0    79.0   \n",
       "4   483.0  1282.0  1081.0   501.0  1166.0  1307.0   482.0   388.0   779.0   \n",
       "\n",
       "       10  \n",
       "0   483.0  \n",
       "1  1096.0  \n",
       "2  1181.0  \n",
       "3    77.0  \n",
       "4  1092.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queriesResult = queryingData(queriesData, 10)\n",
    "queriesResult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def reSizeLists(l1:list, l2:list):\n",
    "    '''resize lists to have the same len'''\n",
    "    if len(l1) < len(l2):\n",
    "        l2 = l2[0:len(l1)]\n",
    "    while len(l1) > len(l2):\n",
    "        l1 = l1[0:len(l2)]\n",
    "\n",
    "    return l1, l2\n",
    "\n",
    "\n",
    "def precWithoutOrder(l1:list,l2:list):\n",
    "    ''' calculate precision witout orering'''\n",
    "    try:\n",
    "        return len(set(l1).intersection(set(l2))) / len(l2)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calcMAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte MAP'''\n",
    "    precisionsAtK:list = []\n",
    "    precisionAtK:float\n",
    "\n",
    "    for i in resData.index:\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "\n",
    "\n",
    "        prec = precision_score(qresArray, resArray, average='micro')\n",
    "        # prec = precWithoutOrder(qresArray, resArray)\n",
    "\n",
    "        precisionsAtK.append(prec)\n",
    "\n",
    "    precisionAtK = sum(precisionsAtK) / len(precisionsAtK)\n",
    "    return precisionAtK\n",
    "\n",
    "def calcAPrecisionAtK(resData:pd.DataFrame, qrelsData: pd.DataFrame):\n",
    "    '''calcualte Average Precision'''\n",
    "    precisionsAtK:list = []\n",
    "\n",
    "    for i in resData.index:\n",
    "        precisionOnQuery = []\n",
    "\n",
    "        resArray = resData.loc[i].to_numpy()\n",
    "        qresArray = qrelsData.loc[qrelsData['.I'] == i+1, 'data'].to_numpy()\n",
    "        \n",
    "        if len(qresArray) == 0: \n",
    "            continue\n",
    "        resArray, qresArray = reSizeLists(resArray, qresArray)\n",
    "\n",
    "        for lenI in range(0,len(qresArray)):\n",
    "\n",
    "            tempRes:list = resArray[0:lenI+1].tolist()\n",
    "            tempQRes:list = qresArray[0:lenI+1].tolist()\n",
    "            precisionOnQuery.append(precision_score(tempQRes, tempRes, average='micro'))\n",
    "\n",
    "        try:\n",
    "            precisionsAtK.append(sum(precisionOnQuery) / len(precisionOnQuery))\n",
    "        except ZeroDivisionError: \n",
    "            precisionsAtK.append(0)\n",
    "    return precisionsAtK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.I</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .I  data\n",
       "0   1    28\n",
       "1   1    35\n",
       "2   1    38\n",
       "3   1    42\n",
       "4   1    43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qrelsFrame = pd.read_csv('../../cisiData/cisiQRels.csv', index_col=[0])\n",
    "qrelsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002631578947368421"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K = 10\n",
    "calcMAPrecisionAtK(queriesResult, qrelsFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.012719298245614033 l1 - qFreq - DFreq\n",
    "0.014181286549707602 l1 - qFreq - DFreq - just .W\n",
    "0.023830409356725146 l1 - qFreq - DFreq - just .W ngram = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10\n",
    "averagePrecision = calcAPrecisionAtK(queriesResult, qrelsFrame)\n",
    "for i in range(0,len(averagePrecision), 2):\n",
    "    print(i+1, end=' - '); print(averagePrecision[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i stoped here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ad1a5a807b944b1335f606d031e49130ad1da3a9de40b9fa5d942006ec880ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IRProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
